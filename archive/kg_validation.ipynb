{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in ./myenv/lib/python3.13/site-packages (3.4.2)\n",
      "Requirement already satisfied: matplotlib in ./myenv/lib/python3.13/site-packages (3.10.1)\n",
      "Requirement already satisfied: pyvis in ./myenv/lib/python3.13/site-packages (0.3.2)\n",
      "Requirement already satisfied: openai in ./myenv/lib/python3.13/site-packages (1.67.0)\n",
      "Requirement already satisfied: python-dotenv in ./myenv/lib/python3.13/site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy in ./myenv/lib/python3.13/site-packages (2.2.5)\n",
      "Requirement already satisfied: torch in ./myenv/lib/python3.13/site-packages (2.7.0)\n",
      "Requirement already satisfied: transformers in ./myenv/lib/python3.13/site-packages (4.49.0)\n",
      "Requirement already satisfied: tqdm in ./myenv/lib/python3.13/site-packages (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub in ./myenv/lib/python3.13/site-packages (0.29.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./myenv/lib/python3.13/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./myenv/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./myenv/lib/python3.13/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./myenv/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./myenv/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./myenv/lib/python3.13/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./myenv/lib/python3.13/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./myenv/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: ipython>=5.3.0 in ./myenv/lib/python3.13/site-packages (from pyvis) (9.0.2)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in ./myenv/lib/python3.13/site-packages (from pyvis) (3.1.6)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in ./myenv/lib/python3.13/site-packages (from pyvis) (4.0.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./myenv/lib/python3.13/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./myenv/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./myenv/lib/python3.13/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./myenv/lib/python3.13/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./myenv/lib/python3.13/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in ./myenv/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./myenv/lib/python3.13/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in ./myenv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in ./myenv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in ./myenv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./myenv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./myenv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./myenv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: filelock in ./myenv/lib/python3.13/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: setuptools in ./myenv/lib/python3.13/site-packages (from torch) (80.3.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./myenv/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: fsspec in ./myenv/lib/python3.13/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./myenv/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./myenv/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./myenv/lib/python3.13/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./myenv/lib/python3.13/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./myenv/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: decorator in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (2.19.1)\n",
      "Requirement already satisfied: stack_data in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in ./myenv/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./myenv/lib/python3.13/site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./myenv/lib/python3.13/site-packages (from jinja2>=2.9.6->pyvis) (3.0.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./myenv/lib/python3.13/site-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in ./myenv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./myenv/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.13/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib/python3.13/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./myenv/lib/python3.13/site-packages (from stack_data->ipython>=5.3.0->pyvis) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./myenv/lib/python3.13/site-packages (from stack_data->ipython>=5.3.0->pyvis) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./myenv/lib/python3.13/site-packages (from stack_data->ipython>=5.3.0->pyvis) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install networkx matplotlib pyvis openai python-dotenv numpy torch transformers tqdm huggingface-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Define your API key securely\n",
    "# @ANISHA - Enter your OpenAI API key here\n",
    "# - If you don't have an API key, you can get one by signing up at https://platform.openai.com/signup\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "\n",
    "\n",
    "def extract_information(text: str):\n",
    "\n",
    "    client = OpenAI()\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # Use an appropriate model\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"\"\"You are an expert at extracting information in structured formats to build a knowledge graph.\n",
    "\n",
    "    Step 1 - Entity detection: Identify all entities in the raw text. Make sure not to miss any out. Entities should be basic and simple, they are akin to Wikipedia nodes.\n",
    "\n",
    "    Step 2 - Coreference resolution: Find all expressions in the text that refer to the same entity. Make sure entities are not duplicated. In particular do not include entities that are more specific versions themselves, e.g. \"a detailed view of jupiter's atmosphere\" and \"jupiter's atmosphere\", only include the most specific version of the entity.\n",
    "\n",
    "    Step 3 - Relation extraction: Identify semantic relationships between the entities you have identified.\n",
    "\n",
    "    Format your response as a JSON array of objects, where each object must have exactly these three fields:\n",
    "    - \"subject\": The first entity\n",
    "    - \"verb\": The relationship between entities\n",
    "    - \"object\": The second entity\n",
    "\n",
    "    Important Tips:\n",
    "    1. Make sure all information is included in the knowledge graph.\n",
    "    2. Each triple must have exactly three non-empty strings.\n",
    "    3. Do not split up related information into separate triples because this could change the meaning.\n",
    "    4. Before adding a triple to the knowledge graph, check if concatenating subject+verb+object makes sense as a sentence. If not, discard it.\n",
    "    5. Keep entities and relationships concise but meaningful.\n",
    "    6. Convert pronouns to their proper noun references when possible.\n",
    "    7. Keep everything lowercase and in present tense when appropriate.\n",
    "    8. The output should be a JSON array of objects, each object containing the fields \"subject\", \"verb\", and \"object\", with the starting and ending tags ```json and ``` respectively.\n",
    "    \"\"\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Use the given format to extract information from the following input: <input>{text}</input>. Skip the preamble and output the result as a JSON array within <json></json> tags.\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    if completion.choices:\n",
    "        response_message = str(completion.choices[0].message.content)\n",
    "        # process response_message from string to JSON\n",
    "        # print(\"DEBUG: response_message = \", response_message)\n",
    "        # if it contains leading and trailing ``` characters, remove them\n",
    "        if response_message.startswith(\"```\") and response_message.endswith(\"```\"):\n",
    "            response_message = response_message[3:-3]\n",
    "        # if it contains leading \"json\" characters, remove them\n",
    "        if response_message.startswith(\"json\"):\n",
    "            response_message = response_message[4:]\n",
    "        response_message = json.loads(response_message)\n",
    "        # print(response_message)\n",
    "        # if the response message is a single JSON object, convert it to a list of JSON objects\n",
    "        if type(response_message) == dict:\n",
    "            response_message = [response_message]\n",
    "        return response_message\n",
    "    else:\n",
    "        print(\"No response received.\")\n",
    "        return []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'subject': 'mihai surdeanu', 'verb': 'is', 'object': 'associate professor'}, {'subject': 'mihai surdeanu', 'verb': 'works in', 'object': 'cognitive science - gidp'}, {'subject': 'mihai surdeanu', 'verb': 'works in', 'object': 'computer science'}, {'subject': 'mihai surdeanu', 'verb': 'works in', 'object': 'bio5 institute'}, {'subject': 'mihai surdeanu', 'verb': 'works at', 'object': 'university of arizona'}, {'subject': 'mihai surdeanu', 'verb': 'earned', 'object': 'ph.d. in computer science'}, {'subject': 'ph.d. in computer science', 'verb': 'is from', 'object': 'southern methodist university'}, {'subject': 'mihai surdeanu', 'verb': 'has', 'object': 'over 15 years of experience'}, {'subject': 'mihai surdeanu', 'verb': 'focuses on', 'object': 'natural language processing'}, {'subject': 'mihai surdeanu', 'verb': 'focuses on', 'object': 'machine learning'}, {'subject': 'mihai surdeanu', 'verb': 'has published', 'object': 'over 80 peer-reviewed articles'}, {'subject': 'mihai surdeanu', 'verb': 'has been', 'object': 'a leader or member of teams'}, {'subject': 'teams', 'verb': 'ranked in', 'object': 'top three'}, {'subject': 'teams', 'verb': 'are at', 'object': 'seven highly competitive international evaluations of end-user NLP systems'}, {'subject': 'miha surdeanu', 'verb': 'has been funded by', 'object': 'several government organizations and private foundations'}]\n",
      "knowledge_graph.html\n"
     ]
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "import json\n",
    "\n",
    "def visualize_json(json_data):\n",
    "    net = Network(height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\")\n",
    "\n",
    "    if isinstance(json_data, str):\n",
    "        data = json.loads(json_data)\n",
    "    else:\n",
    "        data = json_data\n",
    "\n",
    "    for entry in data:\n",
    "        subject = entry.get('subject')\n",
    "        verb = entry.get('verb')\n",
    "        object = entry.get('object')\n",
    "\n",
    "        net.add_node(subject, title=subject, color='skyblue')\n",
    "        net.add_node(object, title=object, color='lightgreen')\n",
    "        net.add_edge(subject, object, title=verb)\n",
    "\n",
    "    net.show(\"knowledge_graph.html\", notebook=False)\n",
    "\n",
    "\n",
    "\n",
    "# Example text to analyze\n",
    "text = \"According to my knowledge, Mihai Surdeanu is an Associate Professor in the departments of Cognitive Science - GIDP, Computer Science, and BIO5 Institute at the University of Arizona. He earned his Ph.D. in Computer Science from Southern Methodist University in 2001 and has over 15 years of experience in building systems driven by natural language processing (NLP) and machine learning. Surdeanu has published over 80 peer-reviewed articles and has been a leader or member of teams that ranked in the top three at seven highly competitive international evaluations of end-user NLP systems such as question answering and information extraction. His work has been funded by several government organizations and private foundations. Surdeanu's research focuses on NLP and machine learning.\"\n",
    "# Extract information from the text\n",
    "json_data = extract_information(text)\n",
    "print(json_data)\n",
    "\n",
    "# Visualize the extracted information as a knowledge graph\n",
    "visualize_json(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knowledge_graph_comparison.html\n"
     ]
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "import json\n",
    "\n",
    "def visualize_comparison(source_json_data, output_json_data, display='both'):\n",
    "    net = Network(height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\")\n",
    "\n",
    "    # Parse JSON data\n",
    "    source_data = json.loads(source_json_data) if isinstance(source_json_data, str) else source_json_data\n",
    "    output_data = json.loads(output_json_data) if isinstance(output_json_data, str) else output_json_data\n",
    "\n",
    "    # Extract nodes and verbs from data\n",
    "    source_nodes = set(entry['subject'] for entry in source_data) | set(entry['object'] for entry in source_data)\n",
    "    output_nodes = set(entry['subject'] for entry in output_data) | set(entry['object'] for entry in output_data)\n",
    "    \n",
    "    # Determine common nodes\n",
    "    common_nodes = source_nodes & output_nodes\n",
    "    \n",
    "    # Function to add nodes and edges to the network\n",
    "    def add_nodes_edges(data, node_color):\n",
    "        for entry in data:\n",
    "            subject, verb, object = entry['subject'], entry['verb'], entry['object']\n",
    "            # Conditionally color nodes if they are common\n",
    "            sub_color = 'yellow' if subject in common_nodes else node_color\n",
    "            obj_color = 'yellow' if object in common_nodes else node_color\n",
    "            net.add_node(subject, title=subject, color=sub_color)\n",
    "            net.add_node(object, title=object, color=obj_color)\n",
    "            net.add_edge(subject, object, title=verb)\n",
    "\n",
    "    # Add source graph nodes and edges\n",
    "    if display in ['source', 'both']:\n",
    "        add_nodes_edges(source_data, 'blue')\n",
    "\n",
    "    # Add output graph nodes and edges\n",
    "    if display in ['output', 'both']:\n",
    "        add_nodes_edges(output_data, 'green')\n",
    "\n",
    "    # Save and show the graph\n",
    "    net.show(\"knowledge_graph_comparison.html\", notebook=False)\n",
    "\n",
    "# Example JSON data for source and output\n",
    "source_json = json.dumps([\n",
    "    {\"subject\": \"Fox\", \"verb\": \"jumps\", \"object\": \"Dog\"},\n",
    "    {\"subject\": \"Dog\", \"verb\": \"barks\", \"object\": \"loudly\"}\n",
    "])\n",
    "\n",
    "output_json = json.dumps([\n",
    "    {\"subject\": \"Fox\", \"verb\": \"runs\", \"object\": \"fast\"},\n",
    "    {\"subject\": \"Dog\", \"verb\": \"barks\", \"object\": \"quietly\"}\n",
    "])\n",
    "\n",
    "# Visualize comparison allowing the user to choose which parts to display\n",
    "visualize_comparison(source_json, output_json, display='both')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source JSON: [{'subject': 'jack', 'verb': 'lives in', 'object': 'a small village'}, {'subject': 'jack', 'verb': 'is known for', 'object': 'his bravery and kindness'}, {'subject': 'jack', 'verb': 'decides to climb', 'object': 'a giant beanstalk'}, {'subject': 'the giant beanstalk', 'verb': 'has grown in', 'object': 'his backyard'}, {'subject': 'jack', 'verb': 'finds', 'object': 'a castle'}, {'subject': 'the castle', 'verb': 'is inhabited by', 'object': 'a giant'}, {'subject': 'the giant', 'verb': 'has', 'object': 'a magical hen'}, {'subject': 'the magical hen', 'verb': 'lays', 'object': 'golden eggs'}, {'subject': 'jack', 'verb': 'manages to steal', 'object': 'the hen'}, {'subject': 'the giant', 'verb': 'chases', 'object': 'jack'}, {'subject': 'jack', 'verb': 'cuts down', 'object': 'the beanstalk'}, {'subject': 'the giant', 'verb': 'falls to', 'object': 'his doom'}, {'subject': 'jack', 'verb': 'returns to', 'object': 'his village'}, {'subject': 'jack', 'verb': 'lives', 'object': 'happily ever after'}, {'subject': 'jack', 'verb': 'returns with', 'object': 'the magical hen'}]\n",
      "Output JSON: [{'subject': 'jack', 'verb': 'lives in', 'object': 'kingman, arizona'}, {'subject': 'jack', 'verb': 'ascends', 'object': 'a massive beanstalk'}, {'subject': 'jack', 'verb': 'discovers', 'object': 'a castle'}, {'subject': 'the castle', 'verb': 'is home to', 'object': 'a formidable giant'}, {'subject': 'the giant', 'verb': 'possesses', 'object': 'a hen with the ability to produce golden eggs'}, {'subject': 'jack', 'verb': 'captures', 'object': 'the hen'}, {'subject': 'the giant', 'verb': 'pursues', 'object': 'jack'}, {'subject': 'jack', 'verb': 'chops down', 'object': 'the beanstalk'}, {'subject': 'the beanstalk', 'verb': 'leads to', 'object': \"the giant's tragic fall and demise\"}, {'subject': 'jack', 'verb': 'returns to', 'object': 'his village'}, {'subject': 'jack', 'verb': 'enjoys', 'object': 'a prosperous and joyful life'}, {'subject': 'jack', 'verb': 'and', 'object': 'the magical hen'}]\n",
      "knowledge_graph_comparison.html\n"
     ]
    }
   ],
   "source": [
    "# Generate source text\n",
    "source_text = \"There was once a boy named Jack who lived in a small village. Jack was known for his bravery and kindness. One day, Jack decided to climb a giant beanstalk that had grown in his backyard. At the top of the beanstalk, he found a castle inhabited by a giant. The giant had a magical hen that laid golden eggs. Jack managed to steal the hen and escape from the giant. The giant chased Jack down the beanstalk, but Jack managed to cut it down, causing the giant to fall to his doom. Jack returned to his village with the magical hen and lived happily ever after.\"\n",
    "\n",
    "# Generate output text with subtle hallucinations\n",
    "output_text = \"In the town of Kingman, Arizona, there lived a courageous and kind-hearted boy named Jack. One adventurous day, he ascended a massive beanstalk sprouting in his backyard. At its peak, Jack discovered a castle, home to a formidable giant. This giant possessed a hen with the ability to produce golden eggs. Jack cleverly captured the hen and fled from the giant's clutches. In a thrilling chase, the giant pursued Jack along the beanstalk. In a daring move, Jack chopped down the beanstalk, leading to the giant's tragic fall and demise. Triumphantly, Jack returned to his village, where he and the magical hen enjoyed a prosperous and joyful life.\"\n",
    "\n",
    "# Extract information from source text\n",
    "source_json = extract_information(source_text)\n",
    "output_json = extract_information(output_text)\n",
    "\n",
    "print(\"Source JSON:\", source_json)\n",
    "print(\"Output JSON:\", output_json)\n",
    "\n",
    "# Compare the graphs\n",
    "visualize_comparison(source_json, output_json, display='both')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The contrasting views of Dr. Lila Montrose and Mr. Edmund Blackwell regarding the upcoming eclipse in Quillhaven illustrate the broader tension between modern scientific inquiry and traditional cultural practices. Dr. Montrose believed in a balanced approach that integrated scientific understanding with a respect for cultural heritage. She focused on educating the community about the scientific mechanics of the eclipse while appreciating its historical and symbolic significance. On the other hand, Mr. Blackwell, who uncovered ancient rituals in a manuscript, advocated for a revival of these traditions, arguing that they were essential to the town's identity and past unity. His stance highlighted a preference for honoring and preserving historical practices over modern scientific methods.\n",
      "\n",
      "To address this conflict, the town of Quillhaven proposed a collaborative solution during a public forum. Both factions—those supporting a modern scientific approach and those favoring traditional rituals—agreed to use the eclipse as a catalyst for dialogue. This led to a consensus that sought to forge a common path which would honor both scientific curiosity and the town’s deep-rooted traditions. This resolution symbolized an effort to blend the benefits of scientific advancements with a reverence for cultural heritage, aiming to unify the community through mutual respect and understanding.\n",
      "Source JSON: [{'subject': 'quillhaven', 'verb': 'is renowned for', 'object': 'historic libraries'}, {'subject': 'quillhaven', 'verb': 'is renowned for', 'object': 'scholarly traditions'}, {'subject': 'total solar eclipse', 'verb': 'is predicted to occur in', 'object': 'quillhaven'}, {'subject': 'total solar eclipse', 'verb': 'is shrouded in', 'object': 'scientific intrigue'}, {'subject': 'total solar eclipse', 'verb': 'is shrouded in', 'object': 'folklore'}, {'subject': 'local legends', 'verb': 'draw on influences from', 'object': 'ancient greek philosophy'}, {'subject': 'local legends', 'verb': 'draw on influences from', 'object': 'indigenous spiritual practices'}, {'subject': 'local legends', 'verb': 'suggest that eclipses hold the power to influence', 'object': 'human thought'}, {'subject': 'local legends', 'verb': 'suggest that eclipses hold the power to influence', 'object': 'communal harmony'}, {'subject': 'dr. lila montrose', 'verb': 'is a respected', 'object': 'astrophysicist'}, {'subject': 'dr. lila montrose', 'verb': 'has dedicated her career to unraveling', 'object': 'mysteries of cosmic events'}, {'subject': 'dr. lila montrose', 'verb': 'sees the eclipse as an opportunity to blend', 'object': 'modern scientific inquiry'}, {'subject': 'dr. lila montrose', 'verb': 'sees the eclipse as an opportunity to blend', 'object': 'cultural heritage'}, {'subject': 'dr. lila montrose', 'verb': 'proposes a series of', 'object': 'public lectures'}, {'subject': 'dr. lila montrose', 'verb': 'proposes a series of', 'object': 'interactive exhibitions'}, {'subject': 'dr. lila montrose', 'verb': 'aims to respect', 'object': 'empirical evidence'}, {'subject': 'dr. lila montrose', 'verb': 'aims to respect', 'object': 'symbolic narratives'}, {'subject': 'mr. edmund blackwell', 'verb': \"is the town's dedicated\", 'object': 'historian'}, {'subject': 'mr. edmund blackwell', 'verb': 'uncovered an ancient manuscript in', 'object': \"quillhaven's old library\"}, {'subject': 'ancient manuscript', 'verb': 'is penned in a mix of', 'object': 'archaic english and latin'}, {'subject': 'ancient manuscript', 'verb': 'detailed elaborate rituals and communal activities performed during', 'object': 'similar eclipses'}, {'subject': 'mr. edmund blackwell', 'verb': 'argues that rituals are intrinsic to', 'object': \"the town's identity\"}, {'subject': 'rituals', 'verb': 'had once fostered', 'object': 'unity and prosperity'}, {'subject': \"mr. edmund blackwell's findings\", 'verb': 'ignited a debate about whether rituals should be', 'object': 'revived'}, {'subject': 'progressive wing', 'verb': 'is led by', 'object': 'dr. lila montrose'}, {'subject': 'progressive wing', 'verb': 'advocates for a balanced modern approach that combines', 'object': 'scientific exploration and cultural respect'}, {'subject': 'conservative faction', 'verb': 'is inspired by', 'object': \"mr. blackwell's manuscript\"}, {'subject': 'conservative faction', 'verb': 'pushes for a return to', 'object': 'traditional rituals'}, {'subject': 'the day of the eclipse', 'verb': 'highlights', 'object': 'an ideological rift'}, {'subject': 'conflicting views', 'verb': 'symbolize a broader struggle between embracing', 'object': 'modernity and preserving historical identity'}, {'subject': 'town leaders', 'verb': 'organize a', 'object': 'public forum'}, {'subject': 'public forum', 'verb': 'features', 'object': 'spirited debates'}, {'subject': 'public forum', 'verb': 'features', 'object': 'passionate speeches'}, {'subject': 'public forum', 'verb': 'concludes with a proposal for', 'object': 'collaboration'}, {'subject': 'both factions', 'verb': 'agree that the eclipse could serve as a catalyst for', 'object': 'dialogue'}, {'subject': 'community', 'verb': 'aims to forge a common path that honors', 'object': 'scientific curiosity and deep-rooted traditions'}]\n",
      "Output JSON: [{'subject': 'dr. lila montrose', 'verb': 'believes in', 'object': 'a balanced approach'}, {'subject': 'dr. lila montrose', 'verb': 'integrates', 'object': 'scientific understanding with cultural heritage'}, {'subject': 'dr. lila montrose', 'verb': 'focuses on', 'object': 'educating the community about the scientific mechanics of the eclipse'}, {'subject': 'dr. lila montrose', 'verb': 'appreciates', 'object': 'the historical and symbolic significance of the eclipse'}, {'subject': 'mr. edmund blackwell', 'verb': 'uncovers', 'object': 'ancient rituals in a manuscript'}, {'subject': 'mr. edmund blackwell', 'verb': 'advocates for', 'object': 'a revival of traditional rituals'}, {'subject': 'mr. edmund blackwell', 'verb': 'argues that', 'object': \"traditional rituals are essential to the town's identity and past unity\"}, {'subject': 'the town of quillhaven', 'verb': 'proposes', 'object': 'a collaborative solution'}, {'subject': 'both factions', 'verb': 'agree to', 'object': 'use the eclipse as a catalyst for dialogue'}, {'subject': 'the consensus', 'verb': 'seeks to', 'object': 'forge a common path'}, {'subject': 'the resolution', 'verb': 'symbolizes', 'object': 'an effort to blend scientific advancements with cultural heritage'}, {'subject': 'the resolution', 'verb': 'aims to', 'object': 'unify the community through mutual respect and understanding'}]\n",
      "Similar Claims:\n",
      "Output Claim: dr. lila montrose believes in a balanced approach\n",
      "Similar Source Claim: {'subject': 'dr. lila montrose', 'verb': 'aims to respect', 'object': 'empirical evidence'} (Similarity: 0.7359707605435631)\n",
      "Similar Source Claim: {'subject': 'dr. lila montrose', 'verb': 'is a respected', 'object': 'astrophysicist'} (Similarity: 0.6710660129822049)\n",
      "Similar Source Claim: {'subject': 'dr. lila montrose', 'verb': 'aims to respect', 'object': 'symbolic narratives'} (Similarity: 0.6588408261319166)\n",
      "\n",
      "Output Claim: dr. lila montrose integrates scientific understanding with cultural heritage\n",
      "Similar Source Claim: {'subject': 'dr. lila montrose', 'verb': 'aims to respect', 'object': 'symbolic narratives'} (Similarity: 0.7585942888961502)\n",
      "Similar Source Claim: {'subject': 'dr. lila montrose', 'verb': 'aims to respect', 'object': 'empirical evidence'} (Similarity: 0.7391644376895438)\n",
      "Similar Source Claim: {'subject': 'dr. lila montrose', 'verb': 'sees the eclipse as an opportunity to blend', 'object': 'cultural heritage'} (Similarity: 0.7385029265353033)\n",
      "\n",
      "Output Claim: dr. lila montrose focuses on educating the community about the scientific mechanics of the eclipse\n",
      "Similar Source Claim: {'subject': 'dr. lila montrose', 'verb': 'sees the eclipse as an opportunity to blend', 'object': 'modern scientific inquiry'} (Similarity: 0.830050575097506)\n",
      "Similar Source Claim: {'subject': 'dr. lila montrose', 'verb': 'sees the eclipse as an opportunity to blend', 'object': 'cultural heritage'} (Similarity: 0.7602135167577678)\n",
      "Similar Source Claim: {'subject': 'dr. lila montrose', 'verb': 'has dedicated her career to unraveling', 'object': 'mysteries of cosmic events'} (Similarity: 0.6868708610210529)\n",
      "\n",
      "Output Claim: dr. lila montrose appreciates the historical and symbolic significance of the eclipse\n",
      "Similar Source Claim: {'subject': 'dr. lila montrose', 'verb': 'sees the eclipse as an opportunity to blend', 'object': 'cultural heritage'} (Similarity: 0.8196746303968732)\n",
      "Similar Source Claim: {'subject': 'dr. lila montrose', 'verb': 'sees the eclipse as an opportunity to blend', 'object': 'modern scientific inquiry'} (Similarity: 0.8087781918034042)\n",
      "Similar Source Claim: {'subject': 'dr. lila montrose', 'verb': 'aims to respect', 'object': 'symbolic narratives'} (Similarity: 0.6407282138914254)\n",
      "\n",
      "Output Claim: mr. edmund blackwell uncovers ancient rituals in a manuscript\n",
      "Similar Source Claim: {'subject': 'mr. edmund blackwell', 'verb': 'uncovered an ancient manuscript in', 'object': \"quillhaven's old library\"} (Similarity: 0.768051667562621)\n",
      "Similar Source Claim: {'subject': \"mr. edmund blackwell's findings\", 'verb': 'ignited a debate about whether rituals should be', 'object': 'revived'} (Similarity: 0.7122330405420545)\n",
      "Similar Source Claim: {'subject': 'mr. edmund blackwell', 'verb': 'argues that rituals are intrinsic to', 'object': \"the town's identity\"} (Similarity: 0.6040888169037621)\n",
      "\n",
      "Output Claim: mr. edmund blackwell advocates for a revival of traditional rituals\n",
      "Similar Source Claim: {'subject': \"mr. edmund blackwell's findings\", 'verb': 'ignited a debate about whether rituals should be', 'object': 'revived'} (Similarity: 0.863302430881532)\n",
      "Similar Source Claim: {'subject': 'mr. edmund blackwell', 'verb': 'argues that rituals are intrinsic to', 'object': \"the town's identity\"} (Similarity: 0.7423530083885262)\n",
      "Similar Source Claim: {'subject': 'conservative faction', 'verb': 'pushes for a return to', 'object': 'traditional rituals'} (Similarity: 0.6215080729419873)\n",
      "\n",
      "Output Claim: mr. edmund blackwell argues that traditional rituals are essential to the town's identity and past unity\n",
      "Similar Source Claim: {'subject': 'mr. edmund blackwell', 'verb': 'argues that rituals are intrinsic to', 'object': \"the town's identity\"} (Similarity: 0.9332501022258963)\n",
      "Similar Source Claim: {'subject': \"mr. edmund blackwell's findings\", 'verb': 'ignited a debate about whether rituals should be', 'object': 'revived'} (Similarity: 0.7203264409059237)\n",
      "Similar Source Claim: {'subject': 'mr. edmund blackwell', 'verb': \"is the town's dedicated\", 'object': 'historian'} (Similarity: 0.7012963405663745)\n",
      "\n",
      "Output Claim: the town of quillhaven proposes a collaborative solution\n",
      "Similar Source Claim: {'subject': 'quillhaven', 'verb': 'is renowned for', 'object': 'historic libraries'} (Similarity: 0.5218953422889222)\n",
      "Similar Source Claim: {'subject': 'public forum', 'verb': 'concludes with a proposal for', 'object': 'collaboration'} (Similarity: 0.5200011384940717)\n",
      "Similar Source Claim: {'subject': 'quillhaven', 'verb': 'is renowned for', 'object': 'scholarly traditions'} (Similarity: 0.4988983695106575)\n",
      "\n",
      "Output Claim: both factions agree to use the eclipse as a catalyst for dialogue\n",
      "Similar Source Claim: {'subject': 'both factions', 'verb': 'agree that the eclipse could serve as a catalyst for', 'object': 'dialogue'} (Similarity: 0.9530253485248316)\n",
      "Similar Source Claim: {'subject': 'the day of the eclipse', 'verb': 'highlights', 'object': 'an ideological rift'} (Similarity: 0.5726714377105391)\n",
      "Similar Source Claim: {'subject': 'local legends', 'verb': 'suggest that eclipses hold the power to influence', 'object': 'communal harmony'} (Similarity: 0.5319239774485823)\n",
      "\n",
      "Output Claim: the consensus seeks to forge a common path\n",
      "Similar Source Claim: {'subject': 'community', 'verb': 'aims to forge a common path that honors', 'object': 'scientific curiosity and deep-rooted traditions'} (Similarity: 0.5880324109277556)\n",
      "Similar Source Claim: {'subject': 'public forum', 'verb': 'concludes with a proposal for', 'object': 'collaboration'} (Similarity: 0.5218622635613295)\n",
      "Similar Source Claim: {'subject': 'both factions', 'verb': 'agree that the eclipse could serve as a catalyst for', 'object': 'dialogue'} (Similarity: 0.448289333104021)\n",
      "\n",
      "Output Claim: the resolution symbolizes an effort to blend scientific advancements with cultural heritage\n",
      "Similar Source Claim: {'subject': 'community', 'verb': 'aims to forge a common path that honors', 'object': 'scientific curiosity and deep-rooted traditions'} (Similarity: 0.5472380617965191)\n",
      "Similar Source Claim: {'subject': 'conflicting views', 'verb': 'symbolize a broader struggle between embracing', 'object': 'modernity and preserving historical identity'} (Similarity: 0.5255266886892433)\n",
      "Similar Source Claim: {'subject': 'progressive wing', 'verb': 'advocates for a balanced modern approach that combines', 'object': 'scientific exploration and cultural respect'} (Similarity: 0.4333499949524228)\n",
      "\n",
      "Output Claim: the resolution aims to unify the community through mutual respect and understanding\n",
      "Similar Source Claim: {'subject': 'community', 'verb': 'aims to forge a common path that honors', 'object': 'scientific curiosity and deep-rooted traditions'} (Similarity: 0.4982535024703971)\n",
      "Similar Source Claim: {'subject': 'public forum', 'verb': 'concludes with a proposal for', 'object': 'collaboration'} (Similarity: 0.44234902941361826)\n",
      "Similar Source Claim: {'subject': 'both factions', 'verb': 'agree that the eclipse could serve as a catalyst for', 'object': 'dialogue'} (Similarity: 0.4173898306019863)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RAG prompt question-answering examples\n",
    "\n",
    "\n",
    "\n",
    "def ask_question(question: str, context: str, model=\"gpt-4-turbo\"):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant specialized in answering questions based on a given context. Your task is to provide accurate and concise answers to the questions asked. If the answer is not present in the context, you should respond with 'The answer is not present in the given context.'\"},\n",
    "            {\"role\": \"system\", \"content\": \"Context: \" + context},\n",
    "            {\"role\": \"user\", \"content\": f\"Question: {question}\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if completion.choices:\n",
    "        response_message = str(completion.choices[0].message.content)\n",
    "        return response_message\n",
    "    else:\n",
    "        print(\"No response received.\")\n",
    "        return None\n",
    "    \n",
    "# Example context and questions\n",
    "context = \"\"\"\n",
    "\n",
    "In the town of Quillhaven—a community renowned for its historic libraries and scholarly traditions—a rare astronomical event was predicted to occur for the first time in over a century. The event, a total solar eclipse, was shrouded in both scientific intrigue and centuries-old folklore. Local legends, drawing on influences from ancient Greek philosophy to indigenous spiritual practices, suggested that eclipses held the power to influence human thought and communal harmony.\n",
    "\n",
    "At the heart of the community’s preparations was Dr. Lila Montrose, a respected astrophysicist whose career had been dedicated to unraveling the mysteries of cosmic events. Dr. Montrose saw the eclipse as an opportunity to blend modern scientific inquiry with the town’s rich cultural heritage. She proposed a series of public lectures and interactive exhibitions designed to educate residents on the mechanics of the eclipse, while also acknowledging its historical and psychological significance. Her balanced approach aimed to respect both empirical evidence and the symbolic narratives that had long captivated the community.\n",
    "\n",
    "Meanwhile, Mr. Edmund Blackwell, the town’s dedicated historian, uncovered an ancient manuscript in the dusty archives of Quillhaven’s old library. The manuscript, penned in a mix of archaic English and Latin, detailed elaborate rituals and communal activities that had been performed during similar eclipses in bygone eras. Blackwell argued that these practices were more than mere superstition—they were intrinsic to the town’s identity and had once fostered unity and prosperity. His findings ignited a fervent debate about whether these ancient rituals should be revived as a way to reconnect with Quillhaven’s storied past.\n",
    "\n",
    "This emerging debate quickly divided the community into two factions. The progressive wing, led by Dr. Montrose, advocated for a balanced, modern approach that combined scientific exploration with cultural respect. In contrast, the conservative faction, inspired by Mr. Blackwell’s manuscript, pushed for a return to the traditional rituals that they believed had been the cornerstone of the town’s former unity and success. As the day of the eclipse drew near, these conflicting views not only highlighted an ideological rift but also symbolized a broader struggle between embracing modernity and preserving historical identity.\n",
    "\n",
    "In a final effort to bridge these divergent perspectives, town leaders organized a public forum. The forum featured spirited debates and passionate speeches, ultimately concluding with a proposal for collaboration. Both factions agreed that the eclipse could serve as a catalyst for dialogue, urging the community to forge a common path that honored both its scientific curiosity and its deep-rooted traditions.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "question = \"Explain how the contrasting views of Dr. Lila Montrose and Mr. Edmund Blackwell regarding the upcoming eclipse illustrate the broader tension between modern scientific inquiry and traditional cultural practices. What solution did the town of Quillhaven ultimately propose to address this conflict?\"\n",
    "\n",
    "# Get the answer to the question\n",
    "answer = ask_question(question, context)\n",
    "print(\"Answer:\", answer)\n",
    "\n",
    "source_json = extract_information(context)\n",
    "output_json = extract_information(answer)\n",
    "\n",
    "print(\"Source JSON:\", source_json)\n",
    "print(\"Output JSON:\", output_json)\n",
    "\n",
    "client_embed = OpenAI(api_key=os.getenv(\"EMBEDDING_API_KEY\"), base_url=os.getenv(\"EMBEDDING_BASE_URL\"))\n",
    "# Find semantically similar claims out of source and output JSON: \"convert these back to text by s-v-o format and compare them\", for each claim in output_json, find the two most similar claims in source_json\n",
    "def find_similar_claims(source_json, output_json):\n",
    "    source_graphs = []\n",
    "    output_graphs = []\n",
    "    for entry in source_json:\n",
    "        source_graphs.append(f\"{entry['subject']} {entry['verb']} {entry['object']}\")\n",
    "    for entry in output_json:\n",
    "        output_graphs.append(f\"{entry['subject']} {entry['verb']} {entry['object']}\")\n",
    "\n",
    "    # create embeddings for source and output graphs\n",
    "    source_embeddings = client_embed.embeddings.create(input=source_graphs, model=\"text-embedding-3-small\")\n",
    "    output_embeddings = client_embed.embeddings.create(input=output_graphs, model=\"text-embedding-3-small\")\n",
    "    # print(\"Source embeddings:\", source_embeddings)\n",
    "    similar_claims = {}\n",
    "\n",
    "    for i, output_entry in enumerate(output_json):\n",
    "        output_embedding = output_embeddings.data[i].embedding  \n",
    "        similarities = []\n",
    "        for j, source_entry in enumerate(source_json):\n",
    "            source_embedding = source_embeddings.data[j].embedding\n",
    "            # Calculate cosine similarity between embeddings\n",
    "            similarity = np.dot(output_embedding, source_embedding) / (np.linalg.norm(output_embedding) * np.linalg.norm(source_embedding))\n",
    "            similarities.append((source_entry, similarity))\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        # print(similarities)\n",
    "        output_entry_string = f\"{output_entry['subject']} {output_entry['verb']} {output_entry['object']}\"\n",
    "        similar_claims[output_entry_string] = similarities[:3]\n",
    "\n",
    "    return similar_claims\n",
    "\n",
    "similar_claims = find_similar_claims(source_json, output_json)\n",
    "\n",
    "print(\"Similar Claims:\")\n",
    "for output_entry, source_entries in similar_claims.items():\n",
    "    print(f\"Output Claim: {output_entry}\")\n",
    "    for source_entry, similarity in source_entries:\n",
    "        print(f\"Similar Source Claim: {source_entry} (Similarity: {similarity})\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: dr. lila montrose aims to respect empirical evidence;dr. lila montrose is a respected astrophysicist;dr. lila montrose aims to respect symbolic narratives\n",
      "Output: dr. lila montrose believes in a balanced approach\n",
      "\n",
      "Input: dr. lila montrose aims to respect symbolic narratives;dr. lila montrose aims to respect empirical evidence;dr. lila montrose sees the eclipse as an opportunity to blend cultural heritage\n",
      "Output: dr. lila montrose integrates scientific understanding with cultural heritage\n",
      "\n",
      "Input: dr. lila montrose sees the eclipse as an opportunity to blend modern scientific inquiry;dr. lila montrose sees the eclipse as an opportunity to blend cultural heritage;dr. lila montrose has dedicated her career to unraveling mysteries of cosmic events\n",
      "Output: dr. lila montrose focuses on educating the community about the scientific mechanics of the eclipse\n",
      "\n",
      "Input: dr. lila montrose sees the eclipse as an opportunity to blend cultural heritage;dr. lila montrose sees the eclipse as an opportunity to blend modern scientific inquiry;dr. lila montrose aims to respect symbolic narratives\n",
      "Output: dr. lila montrose appreciates the historical and symbolic significance of the eclipse\n",
      "\n",
      "Input: mr. edmund blackwell uncovered an ancient manuscript in quillhaven's old library;mr. edmund blackwell's findings ignited a debate about whether rituals should be revived;mr. edmund blackwell argues that rituals are intrinsic to the town's identity\n",
      "Output: mr. edmund blackwell uncovers ancient rituals in a manuscript\n",
      "\n",
      "Input: mr. edmund blackwell's findings ignited a debate about whether rituals should be revived;mr. edmund blackwell argues that rituals are intrinsic to the town's identity;conservative faction pushes for a return to traditional rituals\n",
      "Output: mr. edmund blackwell advocates for a revival of traditional rituals\n",
      "\n",
      "Input: mr. edmund blackwell argues that rituals are intrinsic to the town's identity;mr. edmund blackwell's findings ignited a debate about whether rituals should be revived;mr. edmund blackwell is the town's dedicated historian\n",
      "Output: mr. edmund blackwell argues that traditional rituals are essential to the town's identity and past unity\n",
      "\n",
      "Input: quillhaven is renowned for historic libraries;public forum concludes with a proposal for collaboration;quillhaven is renowned for scholarly traditions\n",
      "Output: the town of quillhaven proposes a collaborative solution\n",
      "\n",
      "Input: both factions agree that the eclipse could serve as a catalyst for dialogue;the day of the eclipse highlights an ideological rift;local legends suggest that eclipses hold the power to influence communal harmony\n",
      "Output: both factions agree to use the eclipse as a catalyst for dialogue\n",
      "\n",
      "Input: community aims to forge a common path that honors scientific curiosity and deep-rooted traditions;public forum concludes with a proposal for collaboration;both factions agree that the eclipse could serve as a catalyst for dialogue\n",
      "Output: the consensus seeks to forge a common path\n",
      "\n",
      "Input: community aims to forge a common path that honors scientific curiosity and deep-rooted traditions;conflicting views symbolize a broader struggle between embracing modernity and preserving historical identity;progressive wing advocates for a balanced modern approach that combines scientific exploration and cultural respect\n",
      "Output: the resolution symbolizes an effort to blend scientific advancements with cultural heritage\n",
      "\n",
      "Input: community aims to forge a common path that honors scientific curiosity and deep-rooted traditions;public forum concludes with a proposal for collaboration;both factions agree that the eclipse could serve as a catalyst for dialogue\n",
      "Output: the resolution aims to unify the community through mutual respect and understanding\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type HHEMv2Config to instantiate a model of type HHEMv2. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Determine if the hypothesis is true given the premise?\n",
      "\n",
      "Premise: dr. lila montrose aims to respect empirical evidence;dr. lila montrose is a respected astrophysicist;dr. lila montrose aims to respect symbolic narratives\n",
      "\n",
      "Hypothesis: dr. lila montrose believes in a balanced approach\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type HHEMv2Config to instantiate a model of type HHEMv2. This is not supported for all configurations of models and can yield errors.\n",
      "You are using a model of type HHEMv2Config to instantiate a model of type HHEMv2. This is not supported for all configurations of models and can yield errors.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.012414200231432915, 0.03012670949101448, 0.014904123730957508, 0.5892153382301331, 0.951510488986969, 0.9311442971229553, 0.20835311710834503, 0.5713628530502319, 0.9764062762260437, 0.8465678691864014, 0.8210894465446472, 0.08822452276945114]\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login  \n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "\n",
    "login(token=os.getenv(\"HUGGINGFACE_TOKEN\"))\n",
    "# Generate pairs from similar claims\n",
    "claim_pairs = []\n",
    "for output_entry, source_entries in similar_claims.items():\n",
    "    source_claims = [f\"{source_entry['subject']} {source_entry['verb']} {source_entry['object']}\" for source_entry, _ in source_entries]\n",
    "    source_claims = \";\".join(source_claims)\n",
    "    claim_pairs.append((source_claims, output_entry))\n",
    "\n",
    "for pair in claim_pairs:\n",
    "    # Print the pairs in a beautiful format\n",
    "    print(\"Input:\", pair[0])\n",
    "    print(\"Output:\", pair[1])\n",
    "    print()\n",
    "\n",
    "# Step 1: Load the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained('vectara/hallucination_evaluation_model', trust_remote_code=True)\n",
    "\n",
    "# Step 2: Evaluate the hallucination model\n",
    "# Prompt the pairs\n",
    "prompt = \"<pad> Determine if the hypothesis is true given the premise?\\n\\nPremise: {text1}\\n\\nHypothesis: {text2}\"\n",
    "input_pairs = [prompt.format(text1=pair[0], text2=pair[1]) for pair in claim_pairs]\n",
    "print(input_pairs[0])\n",
    "\n",
    "# Use text-classification pipeline to predict\n",
    "classifier = pipeline(\n",
    "            \"text-classification\",\n",
    "            model='vectara/hallucination_evaluation_model',\n",
    "            tokenizer=AutoTokenizer.from_pretrained('google/flan-t5-base'),\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "full_scores = classifier(input_pairs, top_k=None) # List[List[Dict[str, float]]]\n",
    "\n",
    "# Optional: Extract the scores for the 'consistent' label\n",
    "simple_scores = [score_dict['score'] for score_for_both_labels in full_scores for score_dict in score_for_both_labels if score_dict['label'] == 'consistent']\n",
    "\n",
    "print(simple_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machine_summaries</th>\n",
       "      <th>human_summaries</th>\n",
       "      <th>relevance</th>\n",
       "      <th>coherence</th>\n",
       "      <th>fluency</th>\n",
       "      <th>consistency</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[donald sterling , nba team last year . sterli...</td>\n",
       "      <td>[V. Stiviano must pay back $2.6 million in gif...</td>\n",
       "      <td>[1.6666666666666667, 1.6666666666666667, 2.333...</td>\n",
       "      <td>[1.3333333333333333, 3.0, 1.0, 2.6666666666666...</td>\n",
       "      <td>[1.0, 4.666666666666667, 4.333333333333333, 4....</td>\n",
       "      <td>[1.0, 2.3333333333333335, 4.666666666666667, 5...</td>\n",
       "      <td>(CNN)Donald Sterling's racist remarks cost him...</td>\n",
       "      <td>cnn-test-404f859482d47c127868964a9a39d1a7645dd2e9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[north pacific gray whale has earned a spot in...</td>\n",
       "      <td>[The whale, Varvara, swam a round trip from Ru...</td>\n",
       "      <td>[2.3333333333333335, 4.666666666666667, 3.6666...</td>\n",
       "      <td>[1.3333333333333333, 4.666666666666667, 3.6666...</td>\n",
       "      <td>[1.0, 5.0, 4.666666666666667, 3.66666666666666...</td>\n",
       "      <td>[1.3333333333333333, 5.0, 5.0, 4.3333333333333...</td>\n",
       "      <td>(CNN)A North Pacific gray whale has earned a s...</td>\n",
       "      <td>cnn-test-4761dc6d8bdf56b9ada97104113dd1bcf4aed3f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[russian fighter jet intercepted a u.s. reconn...</td>\n",
       "      <td>[The incident occurred on April 7 north of Pol...</td>\n",
       "      <td>[4.0, 4.0, 4.0, 3.3333333333333335, 3.33333333...</td>\n",
       "      <td>[3.3333333333333335, 4.333333333333333, 1.6666...</td>\n",
       "      <td>[3.6666666666666665, 4.333333333333333, 5.0, 4...</td>\n",
       "      <td>[5.0, 5.0, 4.666666666666667, 5.0, 5.0, 5.0, 5...</td>\n",
       "      <td>(CNN)After a Russian fighter jet intercepted a...</td>\n",
       "      <td>cnn-test-5139ccfabee55ddb83e7937f5802c0a67aee8975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[michael barnett captured the fire on intersta...</td>\n",
       "      <td>[Country band Lady Antebellum's bus caught fir...</td>\n",
       "      <td>[2.0, 3.0, 2.6666666666666665, 3.3333333333333...</td>\n",
       "      <td>[2.0, 3.0, 2.6666666666666665, 3.3333333333333...</td>\n",
       "      <td>[2.6666666666666665, 5.0, 5.0, 5.0, 5.0, 5.0, ...</td>\n",
       "      <td>[2.3333333333333335, 5.0, 5.0, 5.0, 5.0, 5.0, ...</td>\n",
       "      <td>(CNN)Lady Antebellum singer Hillary Scott's to...</td>\n",
       "      <td>cnn-test-88c2481234e763c9bbc68d0ab1be1d2375c1349a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[deep reddish color caught seattle native tim ...</td>\n",
       "      <td>[Smoke from massive fires in Siberia created f...</td>\n",
       "      <td>[1.6666666666666667, 3.6666666666666665, 3.333...</td>\n",
       "      <td>[1.6666666666666667, 3.6666666666666665, 1.666...</td>\n",
       "      <td>[5.0, 5.0, 5.0, 5.0, 4.666666666666667, 5.0, 5...</td>\n",
       "      <td>[2.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...</td>\n",
       "      <td>(CNN)A fiery sunset greeted people in Washingt...</td>\n",
       "      <td>cnn-test-a02e362c5b8f049848ce718b37b96117485461cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[chelsea have made an offer for fc tokyo 's du...</td>\n",
       "      <td>[Naoki Ogane says that Chelsea have made an of...</td>\n",
       "      <td>[3.0, 4.333333333333333, 4.0, 4.0, 4.333333333...</td>\n",
       "      <td>[2.0, 4.0, 4.333333333333333, 3.66666666666666...</td>\n",
       "      <td>[3.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...</td>\n",
       "      <td>[2.0, 5.0, 5.0, 4.333333333333333, 5.0, 5.0, 5...</td>\n",
       "      <td>Chelsea have made an offer for FC Tokyo's 22-y...</td>\n",
       "      <td>dm-test-f26d8400ae49b90d109c165d0f44b8f6ca253c08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[christopher lawler said he was pinned to a ch...</td>\n",
       "      <td>[Christopher Lawler claims he was pinned to a ...</td>\n",
       "      <td>[5.0, 4.333333333333333, 4.333333333333333, 4....</td>\n",
       "      <td>[3.0, 4.333333333333333, 3.6666666666666665, 4...</td>\n",
       "      <td>[5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 3.0, ...</td>\n",
       "      <td>[5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 1.333...</td>\n",
       "      <td>Police are investigating claims by a former ro...</td>\n",
       "      <td>dm-test-f37fd6e9b6cc18a7132568e307ef3b130931e809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[eden hazard scored a 1-0 lead against manches...</td>\n",
       "      <td>[Eden Hazard scored the opening goal for Chels...</td>\n",
       "      <td>[3.3333333333333335, 3.3333333333333335, 3.666...</td>\n",
       "      <td>[2.0, 2.0, 1.6666666666666667, 1.6666666666666...</td>\n",
       "      <td>[3.3333333333333335, 4.666666666666667, 5.0, 5...</td>\n",
       "      <td>[1.6666666666666667, 5.0, 5.0, 5.0, 4.0, 5.0, ...</td>\n",
       "      <td>After Chelsea forward Eden Hazard had scored g...</td>\n",
       "      <td>dm-test-f468efac7b3c54f8c42c2c81dff108c52ebe0d7d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[evangelos patoulidis is regarded as one of th...</td>\n",
       "      <td>[Evangelos Patoulidis also attracted interest ...</td>\n",
       "      <td>[3.6666666666666665, 4.333333333333333, 4.0, 4...</td>\n",
       "      <td>[2.6666666666666665, 5.0, 5.0, 4.3333333333333...</td>\n",
       "      <td>[4.333333333333333, 5.0, 5.0, 4.66666666666666...</td>\n",
       "      <td>[5.0, 5.0, 5.0, 5.0, 5.0, 4.666666666666667, 5...</td>\n",
       "      <td>Manchester City are keen to sign Anderlecht te...</td>\n",
       "      <td>dm-test-f5fead94ee884800e84a212cc0edc78b11c4ba9f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[woman named only as gemma , has two children ...</td>\n",
       "      <td>[Gemma, 23, has left her children to be raised...</td>\n",
       "      <td>[4.666666666666667, 4.0, 4.333333333333333, 4....</td>\n",
       "      <td>[3.3333333333333335, 2.3333333333333335, 2.666...</td>\n",
       "      <td>[4.0, 5.0, 5.0, 5.0, 5.0, 4.333333333333333, 5...</td>\n",
       "      <td>[5.0, 2.0, 5.0, 4.666666666666667, 5.0, 5.0, 5...</td>\n",
       "      <td>A 23-year-old mother-of-two is at risk of bein...</td>\n",
       "      <td>dm-test-fadabe346fe95d33eee71299e6596754768f5246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    machine_summaries  \\\n",
       "0   [donald sterling , nba team last year . sterli...   \n",
       "1   [north pacific gray whale has earned a spot in...   \n",
       "2   [russian fighter jet intercepted a u.s. reconn...   \n",
       "3   [michael barnett captured the fire on intersta...   \n",
       "4   [deep reddish color caught seattle native tim ...   \n",
       "..                                                ...   \n",
       "95  [chelsea have made an offer for fc tokyo 's du...   \n",
       "96  [christopher lawler said he was pinned to a ch...   \n",
       "97  [eden hazard scored a 1-0 lead against manches...   \n",
       "98  [evangelos patoulidis is regarded as one of th...   \n",
       "99  [woman named only as gemma , has two children ...   \n",
       "\n",
       "                                      human_summaries  \\\n",
       "0   [V. Stiviano must pay back $2.6 million in gif...   \n",
       "1   [The whale, Varvara, swam a round trip from Ru...   \n",
       "2   [The incident occurred on April 7 north of Pol...   \n",
       "3   [Country band Lady Antebellum's bus caught fir...   \n",
       "4   [Smoke from massive fires in Siberia created f...   \n",
       "..                                                ...   \n",
       "95  [Naoki Ogane says that Chelsea have made an of...   \n",
       "96  [Christopher Lawler claims he was pinned to a ...   \n",
       "97  [Eden Hazard scored the opening goal for Chels...   \n",
       "98  [Evangelos Patoulidis also attracted interest ...   \n",
       "99  [Gemma, 23, has left her children to be raised...   \n",
       "\n",
       "                                            relevance  \\\n",
       "0   [1.6666666666666667, 1.6666666666666667, 2.333...   \n",
       "1   [2.3333333333333335, 4.666666666666667, 3.6666...   \n",
       "2   [4.0, 4.0, 4.0, 3.3333333333333335, 3.33333333...   \n",
       "3   [2.0, 3.0, 2.6666666666666665, 3.3333333333333...   \n",
       "4   [1.6666666666666667, 3.6666666666666665, 3.333...   \n",
       "..                                                ...   \n",
       "95  [3.0, 4.333333333333333, 4.0, 4.0, 4.333333333...   \n",
       "96  [5.0, 4.333333333333333, 4.333333333333333, 4....   \n",
       "97  [3.3333333333333335, 3.3333333333333335, 3.666...   \n",
       "98  [3.6666666666666665, 4.333333333333333, 4.0, 4...   \n",
       "99  [4.666666666666667, 4.0, 4.333333333333333, 4....   \n",
       "\n",
       "                                            coherence  \\\n",
       "0   [1.3333333333333333, 3.0, 1.0, 2.6666666666666...   \n",
       "1   [1.3333333333333333, 4.666666666666667, 3.6666...   \n",
       "2   [3.3333333333333335, 4.333333333333333, 1.6666...   \n",
       "3   [2.0, 3.0, 2.6666666666666665, 3.3333333333333...   \n",
       "4   [1.6666666666666667, 3.6666666666666665, 1.666...   \n",
       "..                                                ...   \n",
       "95  [2.0, 4.0, 4.333333333333333, 3.66666666666666...   \n",
       "96  [3.0, 4.333333333333333, 3.6666666666666665, 4...   \n",
       "97  [2.0, 2.0, 1.6666666666666667, 1.6666666666666...   \n",
       "98  [2.6666666666666665, 5.0, 5.0, 4.3333333333333...   \n",
       "99  [3.3333333333333335, 2.3333333333333335, 2.666...   \n",
       "\n",
       "                                              fluency  \\\n",
       "0   [1.0, 4.666666666666667, 4.333333333333333, 4....   \n",
       "1   [1.0, 5.0, 4.666666666666667, 3.66666666666666...   \n",
       "2   [3.6666666666666665, 4.333333333333333, 5.0, 4...   \n",
       "3   [2.6666666666666665, 5.0, 5.0, 5.0, 5.0, 5.0, ...   \n",
       "4   [5.0, 5.0, 5.0, 5.0, 4.666666666666667, 5.0, 5...   \n",
       "..                                                ...   \n",
       "95  [3.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...   \n",
       "96  [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 3.0, ...   \n",
       "97  [3.3333333333333335, 4.666666666666667, 5.0, 5...   \n",
       "98  [4.333333333333333, 5.0, 5.0, 4.66666666666666...   \n",
       "99  [4.0, 5.0, 5.0, 5.0, 5.0, 4.333333333333333, 5...   \n",
       "\n",
       "                                          consistency  \\\n",
       "0   [1.0, 2.3333333333333335, 4.666666666666667, 5...   \n",
       "1   [1.3333333333333333, 5.0, 5.0, 4.3333333333333...   \n",
       "2   [5.0, 5.0, 4.666666666666667, 5.0, 5.0, 5.0, 5...   \n",
       "3   [2.3333333333333335, 5.0, 5.0, 5.0, 5.0, 5.0, ...   \n",
       "4   [2.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...   \n",
       "..                                                ...   \n",
       "95  [2.0, 5.0, 5.0, 4.333333333333333, 5.0, 5.0, 5...   \n",
       "96  [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 1.333...   \n",
       "97  [1.6666666666666667, 5.0, 5.0, 5.0, 4.0, 5.0, ...   \n",
       "98  [5.0, 5.0, 5.0, 5.0, 5.0, 4.666666666666667, 5...   \n",
       "99  [5.0, 2.0, 5.0, 4.666666666666667, 5.0, 5.0, 5...   \n",
       "\n",
       "                                                 text  \\\n",
       "0   (CNN)Donald Sterling's racist remarks cost him...   \n",
       "1   (CNN)A North Pacific gray whale has earned a s...   \n",
       "2   (CNN)After a Russian fighter jet intercepted a...   \n",
       "3   (CNN)Lady Antebellum singer Hillary Scott's to...   \n",
       "4   (CNN)A fiery sunset greeted people in Washingt...   \n",
       "..                                                ...   \n",
       "95  Chelsea have made an offer for FC Tokyo's 22-y...   \n",
       "96  Police are investigating claims by a former ro...   \n",
       "97  After Chelsea forward Eden Hazard had scored g...   \n",
       "98  Manchester City are keen to sign Anderlecht te...   \n",
       "99  A 23-year-old mother-of-two is at risk of bein...   \n",
       "\n",
       "                                                   id  \n",
       "0   cnn-test-404f859482d47c127868964a9a39d1a7645dd2e9  \n",
       "1   cnn-test-4761dc6d8bdf56b9ada97104113dd1bcf4aed3f1  \n",
       "2   cnn-test-5139ccfabee55ddb83e7937f5802c0a67aee8975  \n",
       "3   cnn-test-88c2481234e763c9bbc68d0ab1be1d2375c1349a  \n",
       "4   cnn-test-a02e362c5b8f049848ce718b37b96117485461cf  \n",
       "..                                                ...  \n",
       "95   dm-test-f26d8400ae49b90d109c165d0f44b8f6ca253c08  \n",
       "96   dm-test-f37fd6e9b6cc18a7132568e307ef3b130931e809  \n",
       "97   dm-test-f468efac7b3c54f8c42c2c81dff108c52ebe0d7d  \n",
       "98   dm-test-f5fead94ee884800e84a212cc0edc78b11c4ba9f  \n",
       "99   dm-test-fadabe346fe95d33eee71299e6596754768f5246  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "df = pd.read_parquet(\"hf://datasets/mteb/summeval/data/test-00000-of-00001-35901af5f6649399.parquet\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>machine_summary</th>\n",
       "      <th>consistency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN)Donald Sterling's racist remarks cost him...</td>\n",
       "      <td>donald sterling , nba team last year . sterlin...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN)Donald Sterling's racist remarks cost him...</td>\n",
       "      <td>donald sterling accused stiviano of targeting ...</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(CNN)Donald Sterling's racist remarks cost him...</td>\n",
       "      <td>a los angeles judge has ordered v. stiviano to...</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(CNN)Donald Sterling's racist remarks cost him...</td>\n",
       "      <td>donald sterling 's wife sued stiviano of targe...</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(CNN)Donald Sterling's racist remarks cost him...</td>\n",
       "      <td>donald sterling 's racist remarks cost him an ...</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>A 23-year-old mother-of-two is at risk of bein...</td>\n",
       "      <td>a 23-year-old mother-of-two is at risk of bein...</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>A 23-year-old mother-of-two is at risk of bein...</td>\n",
       "      <td>Gemma , 23 , has two children under five by tw...</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>A 23-year-old mother-of-two is at risk of bein...</td>\n",
       "      <td>gemma , named only as gemma , has two children...</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>A 23-year-old mother-of-two is at risk of bein...</td>\n",
       "      <td>the woman , named only as gemma , has two chil...</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>A 23-year-old mother-of-two is at risk of bein...</td>\n",
       "      <td>the woman has two children under five by two d...</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     (CNN)Donald Sterling's racist remarks cost him...   \n",
       "1     (CNN)Donald Sterling's racist remarks cost him...   \n",
       "2     (CNN)Donald Sterling's racist remarks cost him...   \n",
       "3     (CNN)Donald Sterling's racist remarks cost him...   \n",
       "4     (CNN)Donald Sterling's racist remarks cost him...   \n",
       "...                                                 ...   \n",
       "1595  A 23-year-old mother-of-two is at risk of bein...   \n",
       "1596  A 23-year-old mother-of-two is at risk of bein...   \n",
       "1597  A 23-year-old mother-of-two is at risk of bein...   \n",
       "1598  A 23-year-old mother-of-two is at risk of bein...   \n",
       "1599  A 23-year-old mother-of-two is at risk of bein...   \n",
       "\n",
       "                                        machine_summary  consistency  \n",
       "0     donald sterling , nba team last year . sterlin...     1.000000  \n",
       "1     donald sterling accused stiviano of targeting ...     2.333333  \n",
       "2     a los angeles judge has ordered v. stiviano to...     4.666667  \n",
       "3     donald sterling 's wife sued stiviano of targe...     5.000000  \n",
       "4     donald sterling 's racist remarks cost him an ...     5.000000  \n",
       "...                                                 ...          ...  \n",
       "1595  a 23-year-old mother-of-two is at risk of bein...     5.000000  \n",
       "1596  Gemma , 23 , has two children under five by tw...     5.000000  \n",
       "1597  gemma , named only as gemma , has two children...     5.000000  \n",
       "1598  the woman , named only as gemma , has two chil...     5.000000  \n",
       "1599  the woman has two children under five by two d...     5.000000  \n",
       "\n",
       "[1600 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This dataset contains machine_summaries, human_summaries, text and consistency. Apart from the text, all other columns are lists of strings. The text column contains the original text, while the machine_summaries and human_summaries columns contain the machine-generated and human-written summaries, respectively. The consistency column contains a list of consistency scores for each summary.\n",
    "# Build a new dataframe, where each row contains the text, machine_summary, human_summary, and consistency score for a single summary. This will make it easier to work with the data.\n",
    "# Create a new dataframe with the desired columns\n",
    "\n",
    "# Verify that for each row the lengths of machine_summaries, human_summaries, and consistency are equal.\n",
    "\n",
    "\n",
    "\n",
    "# If it is expand the df\n",
    "df_expanded = pd.DataFrame({\n",
    "    'text': df['text'].repeat(df['machine_summaries'].str.len()).reset_index(drop=True),\n",
    "    'machine_summary': [summary for summaries in df['machine_summaries'] for summary in summaries],\n",
    "    # 'human_summary': [summary for summaries in df['human_summaries'] for summary in summaries],\n",
    "    'consistency': [score for scores in df['consistency'] for score in scores]\n",
    "})\n",
    "\n",
    "\n",
    "df_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change consistency to 0 or 1, 1 if score >=5 else 0\n",
    "df_expanded['weak_consistency'] = df_expanded['consistency'].apply(lambda x: 1 if float(x) >=4  else 0)\n",
    "df_expanded['strong_consistency'] = df_expanded['consistency'].apply(lambda x: 1 if float(x) >= 5 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strong_consistency\n",
      "1    1306\n",
      "0     294\n",
      "Name: count, dtype: int64\n",
      "weak_consistency\n",
      "1    1439\n",
      "0     161\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_expanded['strong_consistency'].value_counts())\n",
    "print(df_expanded['weak_consistency'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type HHEMv2Config to instantiate a model of type HHEMv2. This is not supported for all configurations of models and can yield errors.\n",
      "You are using a model of type HHEMv2Config to instantiate a model of type HHEMv2. This is not supported for all configurations of models and can yield errors.\n",
      "Device set to use mps:0\n",
      "  1%|          | 11/1600 [01:51<3:17:48,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 105/1600 [16:53<3:17:59,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 137/1600 [21:24<3:31:16,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 182/1600 [33:21<4:02:31, 10.26s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 183/1600 [33:27<3:27:35,  8.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 189/1600 [34:29<3:13:56,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 276/1600 [58:47<5:47:45, 15.76s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 317/1600 [1:10:26<4:24:14, 12.36s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 327/1600 [1:12:53<5:02:09, 14.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 522/1600 [2:25:05<11:45:32, 39.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 782/1600 [3:45:44<4:39:17, 20.49s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 790/1600 [3:48:19<3:51:35, 17.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 845/1600 [4:01:25<2:36:22, 12.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 939/1600 [4:22:29<1:44:54,  9.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 997/1600 [4:40:10<3:01:13, 18.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 1058/1600 [4:55:55<1:06:21,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on source failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 1059/1600 [4:56:01<1:04:30,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on source failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1066/1600 [4:57:22<1:23:12,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1070/1600 [4:58:28<1:59:58, 13.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 1122/1600 [5:18:03<2:18:02, 17.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on source failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 1143/1600 [5:22:38<43:45,  5.75s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1146/1600 [5:23:07<1:06:53,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 1188/1600 [5:33:09<1:12:31, 10.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1225/1600 [5:44:41<1:30:16, 14.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1229/1600 [5:45:27<1:10:35, 11.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1234/1600 [5:46:33<1:18:14, 12.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 1303/1600 [6:05:06<57:33, 11.63s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1316/1600 [6:07:49<1:08:54, 14.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 1361/1600 [6:20:22<52:00, 13.06s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 1378/1600 [6:25:02<1:11:50, 19.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 1421/1600 [6:37:10<31:21, 10.51s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 1444/1600 [6:43:39<30:19, 11.66s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1467/1600 [6:51:13<31:21, 14.15s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1485/1600 [6:55:36<23:20, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 1540/1600 [7:08:22<09:16,  9.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1575/1600 [7:13:13<02:39,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1600/1600 [7:17:02<00:00, 16.39s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from json import JSONDecodeError\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "# 1️⃣ One‐time model + tokenizer init\n",
    "_tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-base')\n",
    "_grapheval_clf = pipeline(\n",
    "    \"text-classification\",\n",
    "    model='vectara/hallucination_evaluation_model',\n",
    "    tokenizer=_tokenizer,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# 2️⃣ Prompt template & threshold\n",
    "_PROMPT = (\n",
    "    \"<pad> Determine if the hypothesis is true given the premise?\\n\\n\"\n",
    "    \"Premise: {premise}\\n\\n\"\n",
    "    \"Hypothesis: {hypothesis}\"\n",
    ")\n",
    "_THRESHOLD = 0.5\n",
    "\n",
    "# 3️⃣ Cache for extracted source JSON\n",
    "_source_cache: dict[str, dict] = {}\n",
    "\n",
    "def perform_grapheval(text: str, machine_output: str, threshold: float = _THRESHOLD) -> bool:\n",
    "    # — get or compute source_json (cached)\n",
    "    try:\n",
    "        if text not in _source_cache:\n",
    "            _source_cache[text] = extract_information(text)\n",
    "        source_json = _source_cache[text]\n",
    "    except JSONDecodeError as e:\n",
    "        print(f\"[Warning] extract_information on source failed: {e}\")\n",
    "        return -1\n",
    "\n",
    "    # — always re-extract & compare for the summary\n",
    "    try:\n",
    "        output_json = extract_information(machine_output)\n",
    "    except JSONDecodeError as e:\n",
    "        print(f\"[Warning] extract_information on summary failed: {e}\")\n",
    "        return -1\n",
    "\n",
    "    similar = find_similar_claims(source_json, output_json)\n",
    "    if not similar:\n",
    "        return 1\n",
    "\n",
    "    # — build the prompts\n",
    "    prompts = [\n",
    "        _PROMPT.format(\n",
    "            premise=\";\".join(f\"{s['subject']} {s['verb']} {s['object']}\" for s, _ in sources),\n",
    "            hypothesis=hyp\n",
    "        )\n",
    "        for hyp, sources in similar.items()\n",
    "    ]\n",
    "\n",
    "    # — run the hallucination classifier\n",
    "    results = _grapheval_clf(prompts, top_k=None)\n",
    "    scores = [\n",
    "        entry['score']\n",
    "        for res in results\n",
    "        for entry in res\n",
    "        if entry.get('label', '').lower() == 'consistent'\n",
    "    ]\n",
    "\n",
    "    return 1 if all(score >= threshold for score in scores) else 0\n",
    "\n",
    "# 4️⃣ Apply across your DataFrame with a safe wrapper\n",
    "tqdm.pandas()\n",
    "\n",
    "def safe_eval(row):\n",
    "    try:\n",
    "        return int(perform_grapheval(row['text'], row['machine_summary']))\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Row {row.name} failed evaluation: {e}\")\n",
    "        return -1\n",
    "\n",
    "df_expanded['grapheval_consistency'] = df_expanded.progress_apply(safe_eval, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy Score: 0.53\n",
      "grapheval_consistency\n",
      "0    1471\n",
      "1     129\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get the balanced accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Calculate the balanced accuracy score\n",
    "balanced_accuracy = balanced_accuracy_score(df_expanded['consistency'], df_expanded['grapheval_consistency'])\n",
    "print(f\"Balanced Accuracy Score: {balanced_accuracy:.2f}\")\n",
    "\n",
    "\n",
    "# Find the number of each values in grapheval_consistency\n",
    "grapheval_counts = df_expanded['grapheval_consistency'].value_counts()\n",
    "print(grapheval_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type HHEMv2Config to instantiate a model of type HHEMv2. This is not supported for all configurations of models and can yield errors.\n",
      "You are using a model of type HHEMv2Config to instantiate a model of type HHEMv2. This is not supported for all configurations of models and can yield errors.\n",
      "Device set to use mps:0\n",
      " 22%|██▏       | 347/1600 [19:06<1:25:43,  4.11s/it]"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from json import JSONDecodeError\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# 1️⃣ One‐time model + tokenizer init\n",
    "_tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-base')\n",
    "_grapheval_clf = pipeline(\n",
    "    \"text-classification\",\n",
    "    model='vectara/hallucination_evaluation_model',\n",
    "    tokenizer=_tokenizer,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# 2️⃣ Prompt template & threshold\n",
    "_PROMPT = (\n",
    "    \"<pad> Determine if the hypothesis is true given the premise?\\n\\n\"\n",
    "    \"Premise: {premise}\\n\\n\"\n",
    "    \"Hypothesis: {hypothesis}\"\n",
    ")\n",
    "_THRESHOLD = 0.5\n",
    "\n",
    "# 3️⃣ Cache for extracted source sentences\n",
    "_source_cache: dict[str, list] = {}\n",
    "\n",
    "# Initialize the OpenAI client for embeddings\n",
    "client_embed = OpenAI(api_key=os.getenv(\"EMBEDDING_API_KEY\"), base_url=os.getenv(\"EMBEDDING_BASE_URL\"))\n",
    "\n",
    "def extract_sentences(text: str) -> list:\n",
    "    \"\"\"Extract sentences from the given text.\"\"\"\n",
    "    # Simple sentence splitting - you can improve this as needed\n",
    "    sentences = [s.strip() for s in text.split('.') if s.strip()]\n",
    "    return sentences\n",
    "\n",
    "def find_similar_sentences(source_sentences, output_sentences):\n",
    "    \"\"\"Find semantically similar sentences using embeddings.\"\"\"\n",
    "    # Create embeddings for source and output sentences\n",
    "    source_embeddings = client_embed.embeddings.create(input=source_sentences, model=\"text-embedding-3-small\")\n",
    "    output_embeddings = client_embed.embeddings.create(input=output_sentences, model=\"text-embedding-3-small\")\n",
    "    \n",
    "    similar_sentences = {}\n",
    "\n",
    "    for i, output_sentence in enumerate(output_sentences):\n",
    "        output_embedding = output_embeddings.data[i].embedding\n",
    "        similarities = []\n",
    "        for j, source_sentence in enumerate(source_sentences):\n",
    "            source_embedding = source_embeddings.data[j].embedding\n",
    "            # Calculate cosine similarity between embeddings\n",
    "            similarity = np.dot(output_embedding, source_embedding) / (np.linalg.norm(output_embedding) * np.linalg.norm(source_embedding))\n",
    "            similarities.append((source_sentence, similarity))\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        similar_sentences[output_sentence] = similarities[:3]\n",
    "\n",
    "    return similar_sentences\n",
    "\n",
    "def perform_grapheval(text: str, machine_output: str, threshold: float = _THRESHOLD) -> int:\n",
    "    # — get or compute source sentences (cached)\n",
    "    if text not in _source_cache:\n",
    "        _source_cache[text] = extract_sentences(text)\n",
    "    source_sentences = _source_cache[text]\n",
    "    \n",
    "    # — extract sentences from machine output\n",
    "    output_sentences = extract_sentences(machine_output)\n",
    "    \n",
    "    # — find similar sentences\n",
    "    similar = find_similar_sentences(source_sentences, output_sentences)\n",
    "    \n",
    "    # If no similarities found, mark as inconsistent (original returned 1 here, keeping that logic)\n",
    "    if not similar:\n",
    "        return 1\n",
    "        \n",
    "    # — build the prompts for evaluation\n",
    "    prompts = []\n",
    "    for output_sent, sources in similar.items():\n",
    "        # Create premise from source sentences (using only the sentences, not the similarity scores)\n",
    "        premise = \";\".join([s for s, _ in sources])\n",
    "        hypothesis = output_sent\n",
    "        prompts.append(_PROMPT.format(premise=premise, hypothesis=hypothesis))\n",
    "    \n",
    "    # — run the hallucination classifier\n",
    "    results = _grapheval_clf(prompts, top_k=None)\n",
    "    scores = [\n",
    "        entry['score']\n",
    "        for res in results\n",
    "        for entry in res\n",
    "        if entry.get('label', '').lower() == 'consistent'\n",
    "    ]\n",
    "    \n",
    "    # Return consistent (1) if all sentences are consistent with threshold, otherwise inconsistent (0)\n",
    "    return 1 if all(score >= threshold for score in scores) else 0\n",
    "\n",
    "# 4️⃣ Apply across your DataFrame with a safe wrapper\n",
    "tqdm.pandas()\n",
    "\n",
    "def safe_eval(row):\n",
    "    try:\n",
    "        return int(perform_grapheval(row['text'], row['machine_summary']))\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Row {row.name} failed evaluation: {e}\")\n",
    "        return -1\n",
    "\n",
    "df_expanded['grapheval_consistency'] = df_expanded.progress_apply(safe_eval, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from json import JSONDecodeError\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1️⃣ One‐time model + tokenizer init\n",
    "_tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-base')\n",
    "_grapheval_clf = pipeline(\n",
    "    \"text-classification\",\n",
    "    model='vectara/hallucination_evaluation_model',\n",
    "    tokenizer=_tokenizer,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Load NER model for entity detection\n",
    "ner_tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "ner_model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "ner_pipeline = pipeline(\"ner\", model=ner_model, tokenizer=ner_tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "# Load Sentence Transformer model for embeddings\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')  # Smaller, efficient model\n",
    "\n",
    "# 2️⃣ Prompt template & threshold\n",
    "_PROMPT = (\n",
    "    \"<pad> Determine if the hypothesis is true given the premise?\\n\\n\"\n",
    "    \"Premise: {premise}\\n\\n\"\n",
    "    \"Hypothesis: {hypothesis}\"\n",
    ")\n",
    "_THRESHOLD = 0.5\n",
    "\n",
    "# 3️⃣ Cache for extracted source sentences\n",
    "_source_cache: dict[str, list] = {}\n",
    "\n",
    "def replace_pronouns_with_nouns(text):\n",
    "    \"\"\"Replace pronouns with their referent nouns using a rule-based approach with NER support.\"\"\"\n",
    "    # Define common pronouns we want to replace\n",
    "    pronouns = [\"he\", \"she\", \"it\", \"they\", \"his\", \"her\", \"its\", \"their\", \"them\", \"himself\", \"herself\", \"itself\", \"themselves\"]\n",
    "    pronoun_pattern = r'\\b(' + '|'.join(pronouns) + r')\\b'\n",
    "    \n",
    "    # Extract entities using NER\n",
    "    entities = ner_pipeline(text)\n",
    "    \n",
    "    # Filter to focus on persons and organizations (the most common antecedents for pronouns)\n",
    "    persons_orgs = [entity for entity in entities if entity[\"entity_group\"] in [\"PER\", \"ORG\"]]\n",
    "    \n",
    "    if not persons_orgs:\n",
    "        return text  # No suitable entities found\n",
    "    \n",
    "    # Map each sentence with its entities\n",
    "    sentences = [s.strip() for s in re.split(r'[.!?]', text) if s.strip()]\n",
    "    sentence_entities = {}\n",
    "    \n",
    "    for i, sentence in enumerate(sentences):\n",
    "        sentence_entities[i] = []\n",
    "        for entity in persons_orgs:\n",
    "            if entity[\"word\"] in sentence:\n",
    "                sentence_entities[i].append(entity)\n",
    "    \n",
    "    # Process text to replace pronouns\n",
    "    processed_text = \"\"\n",
    "    current_entity_idx = 0\n",
    "    \n",
    "    for i, sentence in enumerate(sentences):\n",
    "        # Find entities in current and previous sentences\n",
    "        current_entities = sentence_entities.get(i, [])\n",
    "        prev_entities = sentence_entities.get(i-1, []) if i > 0 else []\n",
    "        \n",
    "        # Get the most recent entity to use for pronoun replacement\n",
    "        entity_to_use = None\n",
    "        if current_entities:\n",
    "            entity_to_use = current_entities[0][\"word\"]\n",
    "        elif prev_entities:\n",
    "            entity_to_use = prev_entities[0][\"word\"]\n",
    "        \n",
    "        # Replace pronouns if we have an entity\n",
    "        if entity_to_use:\n",
    "            processed_sentence = re.sub(\n",
    "                pronoun_pattern, \n",
    "                entity_to_use, \n",
    "                sentence, \n",
    "                flags=re.IGNORECASE\n",
    "            )\n",
    "        else:\n",
    "            processed_sentence = sentence\n",
    "        \n",
    "        processed_text += processed_sentence + \". \"\n",
    "    \n",
    "    return processed_text.strip()\n",
    "\n",
    "def extract_sentences(text: str) -> list:\n",
    "    \"\"\"Extract sentences from the given text with pronouns replaced.\"\"\"\n",
    "    # First replace pronouns with nouns\n",
    "    text_with_nouns = replace_pronouns_with_nouns(text)\n",
    "    \n",
    "    # Then extract sentences\n",
    "    sentences = [s.strip() for s in re.split(r'[.!?]', text_with_nouns) if s.strip()]\n",
    "    return sentences\n",
    "\n",
    "def find_similar_sentences(source_sentences, output_sentences):\n",
    "    \"\"\"Find semantically similar sentences using sentence transformer embeddings.\"\"\"\n",
    "    # Create embeddings for source and output sentences\n",
    "    source_embeddings = embedding_model.encode(source_sentences)\n",
    "    output_embeddings = embedding_model.encode(output_sentences)\n",
    "    \n",
    "    similar_sentences = {}\n",
    "\n",
    "    for i, output_sentence in enumerate(output_sentences):\n",
    "        output_embedding = output_embeddings[i]\n",
    "        similarities = []\n",
    "        for j, source_sentence in enumerate(source_sentences):\n",
    "            source_embedding = source_embeddings[j]\n",
    "            # Calculate cosine similarity between embeddings\n",
    "            similarity = np.dot(output_embedding, source_embedding) / (np.linalg.norm(output_embedding) * np.linalg.norm(source_embedding))\n",
    "            similarities.append((source_sentence, similarity))\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        similar_sentences[output_sentence] = similarities[:3]\n",
    "\n",
    "    return similar_sentences\n",
    "\n",
    "def perform_grapheval(text: str, machine_output: str, threshold: float = _THRESHOLD) -> int:\n",
    "    # — get or compute source sentences (cached)\n",
    "    if text not in _source_cache:\n",
    "        _source_cache[text] = extract_sentences(text)\n",
    "    source_sentences = _source_cache[text]\n",
    "    \n",
    "    # — extract sentences from machine output\n",
    "    output_sentences = extract_sentences(machine_output)\n",
    "    \n",
    "    # — find similar sentences\n",
    "    similar = find_similar_sentences(source_sentences, output_sentences)\n",
    "    \n",
    "    # If no similarities found, mark as inconsistent (original returned 1 here, keeping that logic)\n",
    "    if not similar:\n",
    "        return 1\n",
    "        \n",
    "    # — build the prompts for evaluation\n",
    "    prompts = []\n",
    "    for output_sent, sources in similar.items():\n",
    "        # Create premise from source sentences (using only the sentences, not the similarity scores)\n",
    "        premise = \";\".join([s for s, _ in sources])\n",
    "        hypothesis = output_sent\n",
    "        prompts.append(_PROMPT.format(premise=premise, hypothesis=hypothesis))\n",
    "    \n",
    "    # — run the hallucination classifier\n",
    "    results = _grapheval_clf(prompts, top_k=None)\n",
    "    scores = [\n",
    "        entry['score']\n",
    "        for res in results\n",
    "        for entry in res\n",
    "        if entry.get('label', '').lower() == 'consistent'\n",
    "    ]\n",
    "    \n",
    "    # Return consistent (1) if all sentences are consistent with threshold, otherwise inconsistent (0)\n",
    "    return 1 if all(score >= threshold for score in scores) else 0\n",
    "\n",
    "# 4️⃣ Apply across your DataFrame with a safe wrapper\n",
    "tqdm.pandas()\n",
    "\n",
    "def safe_eval(row):\n",
    "    try:\n",
    "        return int(perform_grapheval(row['text'], row['machine_summary']))\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Row {row.name} failed evaluation: {e}\")\n",
    "        return -1\n",
    "\n",
    "df_expanded['grapheval_consistency'] = df_expanded.progress_apply(safe_eval, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

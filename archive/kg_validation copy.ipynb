{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in ./myenv/lib/python3.13/site-packages (3.4.2)\n",
      "Requirement already satisfied: matplotlib in ./myenv/lib/python3.13/site-packages (3.10.1)\n",
      "Requirement already satisfied: pyvis in ./myenv/lib/python3.13/site-packages (0.3.2)\n",
      "Requirement already satisfied: openai in ./myenv/lib/python3.13/site-packages (1.67.0)\n",
      "Requirement already satisfied: python-dotenv in ./myenv/lib/python3.13/site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy in ./myenv/lib/python3.13/site-packages (2.2.5)\n",
      "Requirement already satisfied: torch in ./myenv/lib/python3.13/site-packages (2.7.0)\n",
      "Requirement already satisfied: transformers in ./myenv/lib/python3.13/site-packages (4.49.0)\n",
      "Requirement already satisfied: tqdm in ./myenv/lib/python3.13/site-packages (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub in ./myenv/lib/python3.13/site-packages (0.29.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./myenv/lib/python3.13/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./myenv/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./myenv/lib/python3.13/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./myenv/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./myenv/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./myenv/lib/python3.13/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./myenv/lib/python3.13/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./myenv/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: ipython>=5.3.0 in ./myenv/lib/python3.13/site-packages (from pyvis) (9.0.2)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in ./myenv/lib/python3.13/site-packages (from pyvis) (3.1.6)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in ./myenv/lib/python3.13/site-packages (from pyvis) (4.0.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./myenv/lib/python3.13/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./myenv/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./myenv/lib/python3.13/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./myenv/lib/python3.13/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./myenv/lib/python3.13/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in ./myenv/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./myenv/lib/python3.13/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: filelock in ./myenv/lib/python3.13/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: setuptools in ./myenv/lib/python3.13/site-packages (from torch) (77.0.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./myenv/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: fsspec in ./myenv/lib/python3.13/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./myenv/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./myenv/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./myenv/lib/python3.13/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./myenv/lib/python3.13/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./myenv/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: idna>=2.8 in ./myenv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in ./myenv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in ./myenv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./myenv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: decorator in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (2.19.1)\n",
      "Requirement already satisfied: stack_data in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (5.14.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./myenv/lib/python3.13/site-packages (from jinja2>=2.9.6->pyvis) (3.0.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./myenv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./myenv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in ./myenv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./myenv/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.13/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib/python3.13/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./myenv/lib/python3.13/site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./myenv/lib/python3.13/site-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./myenv/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./myenv/lib/python3.13/site-packages (from stack_data->ipython>=5.3.0->pyvis) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./myenv/lib/python3.13/site-packages (from stack_data->ipython>=5.3.0->pyvis) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./myenv/lib/python3.13/site-packages (from stack_data->ipython>=5.3.0->pyvis) (0.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install networkx matplotlib pyvis openai python-dotenv numpy torch transformers tqdm huggingface-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Define your API key securely\n",
    "# @ANISHA - Enter your OpenAI API key here\n",
    "# - If you don't have an API key, you can get one by signing up at https://platform.openai.com/signup\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "\n",
    "\n",
    "def extract_information(text: str):\n",
    "\n",
    "    client = OpenAI()\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",  # Use an appropriate model\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"\"\"You are an expert at extracting information in structured formats to build a knowledge graph.\n",
    "\n",
    "    Step 1 - Entity detection: Identify all entities in the raw text. Make sure not to miss any out. Entities should be basic and simple, they are akin to Wikipedia nodes.\n",
    "\n",
    "    Step 2 - Coreference resolution: Find all expressions in the text that refer to the same entity. Make sure entities are not duplicated. In particular do not include entities that are more specific versions themselves, e.g. \"a detailed view of jupiter's atmosphere\" and \"jupiter's atmosphere\", only include the most specific version of the entity.\n",
    "\n",
    "    Step 3 - Relation extraction: Identify semantic relationships between the entities you have identified.\n",
    "\n",
    "    Format your response as a JSON array of objects, where each object must have exactly these three fields:\n",
    "    - \"subject\": The first entity\n",
    "    - \"verb\": The relationship between entities\n",
    "    - \"object\": The second entity\n",
    "\n",
    "    Important Tips:\n",
    "    1. Make sure all information is included in the knowledge graph.\n",
    "    2. Each triple must have exactly three non-empty strings.\n",
    "    3. Do not split up related information into separate triples because this could change the meaning.\n",
    "    4. Before adding a triple to the knowledge graph, check if concatenating subject+verb+object makes sense as a sentence. If not, discard it.\n",
    "    5. Keep entities and relationships concise but meaningful.\n",
    "    6. Convert pronouns to their proper noun references when possible.\n",
    "    7. Keep everything lowercase and in present tense when appropriate.\n",
    "    8. The output should be a JSON array of objects, each object containing the fields \"subject\", \"verb\", and \"object\", with the starting and ending tags ```json and ``` respectively.\n",
    "    \"\"\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Use the given format to extract information from the following input: <input>{text}</input>. Skip the preamble and output the result as a JSON array within <json></json> tags.\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    if completion.choices:\n",
    "        response_message = str(completion.choices[0].message.content)\n",
    "        # process response_message from string to JSON\n",
    "        # print(\"DEBUG: response_message = \", response_message)\n",
    "        # if it contains leading and trailing ``` characters, remove them\n",
    "        if response_message.startswith(\"```\") and response_message.endswith(\"```\"):\n",
    "            response_message = response_message[3:-3]\n",
    "        # if it contains leading \"json\" characters, remove them\n",
    "        if response_message.startswith(\"json\"):\n",
    "            response_message = response_message[4:]\n",
    "        response_message = json.loads(response_message)\n",
    "        # print(response_message)\n",
    "        # if the response message is a single JSON object, convert it to a list of JSON objects\n",
    "        if type(response_message) == dict:\n",
    "            response_message = [response_message]\n",
    "        return response_message\n",
    "    else:\n",
    "        print(\"No response received.\")\n",
    "        return []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'subject': 'mihai surdeanu', 'verb': 'is', 'object': 'associate professor'}, {'subject': 'associate professor', 'verb': 'in', 'object': 'departments of cognitive science - gidp, computer science, and bio5 institute'}, {'subject': 'departments of cognitive science - gidp, computer science, and bio5 institute', 'verb': 'at', 'object': 'university of arizona'}, {'subject': 'mihai surdeanu', 'verb': 'earned', 'object': 'ph.d. in computer science'}, {'subject': 'ph.d. in computer science', 'verb': 'from', 'object': 'southern methodist university'}, {'subject': 'ph.d. in computer science', 'verb': 'in', 'object': '2001'}, {'subject': 'mihai surdeanu', 'verb': 'has', 'object': 'over 15 years of experience'}, {'subject': 'systems', 'verb': 'driven by', 'object': 'natural language processing and machine learning'}, {'subject': 'mihai surdeanu', 'verb': 'published', 'object': 'over 80 peer-reviewed articles'}, {'subject': 'mihai surdeanu', 'verb': 'is a leader or member of teams ranked in', 'object': 'top three at seven international evaluations of nlp systems'}, {'subject': 'evaluations of nlp systems', 'verb': 'such as', 'object': 'question answering and information extraction'}, {'subject': \"mihai surdeanu's work\", 'verb': 'funded by', 'object': 'several government organizations and private foundations'}, {'subject': \"mihai surdeanu's research\", 'verb': 'focuses on', 'object': 'natural language processing and machine learning'}]\n",
      "knowledge_graph.html\n"
     ]
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "import json\n",
    "\n",
    "def visualize_json(json_data):\n",
    "    net = Network(height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\")\n",
    "\n",
    "    if isinstance(json_data, str):\n",
    "        data = json.loads(json_data)\n",
    "    else:\n",
    "        data = json_data\n",
    "\n",
    "    for entry in data:\n",
    "        subject = entry.get('subject')\n",
    "        verb = entry.get('verb')\n",
    "        object = entry.get('object')\n",
    "\n",
    "        net.add_node(subject, title=subject, color='skyblue')\n",
    "        net.add_node(object, title=object, color='lightgreen')\n",
    "        net.add_edge(subject, object, title=verb)\n",
    "\n",
    "    net.show(\"knowledge_graph.html\", notebook=False)\n",
    "\n",
    "\n",
    "\n",
    "# Example text to analyze\n",
    "text = \"According to my knowledge, Mihai Surdeanu is an Associate Professor in the departments of Cognitive Science - GIDP, Computer Science, and BIO5 Institute at the University of Arizona. He earned his Ph.D. in Computer Science from Southern Methodist University in 2001 and has over 15 years of experience in building systems driven by natural language processing (NLP) and machine learning. Surdeanu has published over 80 peer-reviewed articles and has been a leader or member of teams that ranked in the top three at seven highly competitive international evaluations of end-user NLP systems such as question answering and information extraction. His work has been funded by several government organizations and private foundations. Surdeanu's research focuses on NLP and machine learning.\"\n",
    "# Extract information from the text\n",
    "json_data = extract_information(text)\n",
    "print(json_data)\n",
    "\n",
    "# Visualize the extracted information as a knowledge graph\n",
    "visualize_json(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knowledge_graph_comparison.html\n"
     ]
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "import json\n",
    "\n",
    "def visualize_comparison(source_json_data, output_json_data, display='both'):\n",
    "    net = Network(height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\")\n",
    "\n",
    "    # Parse JSON data\n",
    "    source_data = json.loads(source_json_data) if isinstance(source_json_data, str) else source_json_data\n",
    "    output_data = json.loads(output_json_data) if isinstance(output_json_data, str) else output_json_data\n",
    "\n",
    "    # Extract nodes and verbs from data\n",
    "    source_nodes = set(entry['subject'] for entry in source_data) | set(entry['object'] for entry in source_data)\n",
    "    output_nodes = set(entry['subject'] for entry in output_data) | set(entry['object'] for entry in output_data)\n",
    "    \n",
    "    # Determine common nodes\n",
    "    common_nodes = source_nodes & output_nodes\n",
    "    \n",
    "    # Function to add nodes and edges to the network\n",
    "    def add_nodes_edges(data, node_color):\n",
    "        for entry in data:\n",
    "            subject, verb, object = entry['subject'], entry['verb'], entry['object']\n",
    "            # Conditionally color nodes if they are common\n",
    "            sub_color = 'yellow' if subject in common_nodes else node_color\n",
    "            obj_color = 'yellow' if object in common_nodes else node_color\n",
    "            net.add_node(subject, title=subject, color=sub_color)\n",
    "            net.add_node(object, title=object, color=obj_color)\n",
    "            net.add_edge(subject, object, title=verb)\n",
    "\n",
    "    # Add source graph nodes and edges\n",
    "    if display in ['source', 'both']:\n",
    "        add_nodes_edges(source_data, 'blue')\n",
    "\n",
    "    # Add output graph nodes and edges\n",
    "    if display in ['output', 'both']:\n",
    "        add_nodes_edges(output_data, 'green')\n",
    "\n",
    "    # Save and show the graph\n",
    "    net.show(\"knowledge_graph_comparison.html\", notebook=False)\n",
    "\n",
    "# Example JSON data for source and output\n",
    "source_json = json.dumps([\n",
    "    {\"subject\": \"Fox\", \"verb\": \"jumps\", \"object\": \"Dog\"},\n",
    "    {\"subject\": \"Dog\", \"verb\": \"barks\", \"object\": \"loudly\"}\n",
    "])\n",
    "\n",
    "output_json = json.dumps([\n",
    "    {\"subject\": \"Fox\", \"verb\": \"runs\", \"object\": \"fast\"},\n",
    "    {\"subject\": \"Dog\", \"verb\": \"barks\", \"object\": \"quietly\"}\n",
    "])\n",
    "\n",
    "# Visualize comparison allowing the user to choose which parts to display\n",
    "visualize_comparison(source_json, output_json, display='both')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source JSON: [{'subject': 'jack', 'verb': 'live in', 'object': 'small village'}, {'subject': 'jack', 'verb': 'be known for', 'object': 'bravery and kindness'}, {'subject': 'jack', 'verb': 'decide to climb', 'object': 'giant beanstalk'}, {'subject': 'giant beanstalk', 'verb': 'grow in', 'object': \"jack's backyard\"}, {'subject': 'jack', 'verb': 'find', 'object': 'castle'}, {'subject': 'castle', 'verb': 'inhabit by', 'object': 'giant'}, {'subject': 'giant', 'verb': 'have', 'object': 'magical hen'}, {'subject': 'magical hen', 'verb': 'lay', 'object': 'golden eggs'}, {'subject': 'jack', 'verb': 'steal', 'object': 'magical hen'}, {'subject': 'jack', 'verb': 'escape from', 'object': 'giant'}, {'subject': 'giant', 'verb': 'chase', 'object': 'jack'}, {'subject': 'jack', 'verb': 'cut down', 'object': 'beanstalk'}, {'subject': 'beanstalk', 'verb': 'cause', 'object': \"giant's doom\"}, {'subject': 'jack', 'verb': 'return to', 'object': 'village'}, {'subject': 'jack', 'verb': 'live with', 'object': 'magical hen'}]\n",
      "Output JSON: [{'subject': 'kingman, arizona', 'verb': 'is the location of', 'object': \"jack's residence\"}, {'subject': 'jack', 'verb': 'lives in', 'object': 'kingman, arizona'}, {'subject': 'jack', 'verb': 'ascends', 'object': 'massive beanstalk'}, {'subject': 'beanstalk', 'verb': 'is located in', 'object': \"jack's backyard\"}, {'subject': 'jack', 'verb': 'discovers', 'object': 'castle'}, {'subject': 'castle', 'verb': 'is home to', 'object': 'formidable giant'}, {'subject': 'giant', 'verb': 'possesses', 'object': 'hen with the ability to produce golden eggs'}, {'subject': 'jack', 'verb': 'captures', 'object': 'hen'}, {'subject': 'jack', 'verb': 'flees from', 'object': 'giant'}, {'subject': 'giant', 'verb': 'pursues', 'object': 'jack'}, {'subject': 'jack', 'verb': 'chops down', 'object': 'beanstalk'}, {'subject': \"beanstalk's fall\", 'verb': 'leads to', 'object': \"giant's demise\"}, {'subject': 'jack', 'verb': 'returns to', 'object': 'village'}, {'subject': 'jack and hen', 'verb': 'enjoy', 'object': 'prosperous and joyful life'}]\n",
      "knowledge_graph_comparison.html\n"
     ]
    }
   ],
   "source": [
    "# Generate source text\n",
    "source_text = \"There was once a boy named Jack who lived in a small village. Jack was known for his bravery and kindness. One day, Jack decided to climb a giant beanstalk that had grown in his backyard. At the top of the beanstalk, he found a castle inhabited by a giant. The giant had a magical hen that laid golden eggs. Jack managed to steal the hen and escape from the giant. The giant chased Jack down the beanstalk, but Jack managed to cut it down, causing the giant to fall to his doom. Jack returned to his village with the magical hen and lived happily ever after.\"\n",
    "\n",
    "# Generate output text with subtle hallucinations\n",
    "output_text = \"In the town of Kingman, Arizona, there lived a courageous and kind-hearted boy named Jack. One adventurous day, he ascended a massive beanstalk sprouting in his backyard. At its peak, Jack discovered a castle, home to a formidable giant. This giant possessed a hen with the ability to produce golden eggs. Jack cleverly captured the hen and fled from the giant's clutches. In a thrilling chase, the giant pursued Jack along the beanstalk. In a daring move, Jack chopped down the beanstalk, leading to the giant's tragic fall and demise. Triumphantly, Jack returned to his village, where he and the magical hen enjoyed a prosperous and joyful life.\"\n",
    "\n",
    "# Extract information from source text\n",
    "source_json = extract_information(source_text)\n",
    "output_json = extract_information(output_text)\n",
    "\n",
    "print(\"Source JSON:\", source_json)\n",
    "print(\"Output JSON:\", output_json)\n",
    "\n",
    "# Compare the graphs\n",
    "visualize_comparison(source_json, output_json, display='both')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Dr. Lila Montrose and Mr. Edmund Blackwell represent the tension between modern scientific inquiry and traditional cultural practices. Dr. Montrose, with her background in astrophysics, approached the eclipse with a focus on scientific education and understanding, emphasizing the mechanics of the eclipse and its psychological significance within a modern framework. In contrast, Mr. Blackwell, as a historian, viewed the eclipse through the lens of tradition and culture, advocating for the revival of ancient rituals documented in a manuscript he found, which he believed were essential to the town's identity and historical unity.\n",
      "\n",
      "The town of Quillhaven proposed a solution to this conflict by organizing a public forum that encouraged dialogue and collaboration between both perspectives. The forum allowed for debates and discussions, which concluded with both factions agreeing that the eclipse could be a catalyst for unity, bridging modern scientific methods with the respect for cultural heritage. This collaborative approach aimed to honor both the town’s scientific curiosity and its deep-rooted traditions, fostering a common path forward.\n",
      "Source JSON: [{'subject': 'quillhaven', 'verb': 'be renowned for', 'object': 'historic libraries and scholarly traditions'}, {'subject': 'total solar eclipse', 'verb': 'occur in', 'object': 'quillhaven'}, {'subject': 'local legends', 'verb': 'suggest', 'object': 'eclipses influence human thought and communal harmony'}, {'subject': 'dr. lila montrose', 'verb': 'be', 'object': 'respected astrophysicist'}, {'subject': 'dr. lila montrose', 'verb': 'propose', 'object': 'public lectures and interactive exhibitions'}, {'subject': 'mr. edmund blackwell', 'verb': 'uncover', 'object': 'ancient manuscript'}, {'subject': 'ancient manuscript', 'verb': 'detail', 'object': 'rituals and communal activities during eclipses'}, {'subject': 'mr. edmund blackwell', 'verb': 'argue', 'object': 'rituals fostered unity and prosperity'}, {'subject': 'progressive wing', 'verb': 'advocate for', 'object': 'modern approach combining scientific exploration with cultural respect'}, {'subject': 'conservative faction', 'verb': 'push for', 'object': 'return to traditional rituals'}, {'subject': 'town leaders', 'verb': 'organize', 'object': 'public forum'}, {'subject': 'forum', 'verb': 'conclude with', 'object': 'proposal for collaboration'}, {'subject': 'eclipse', 'verb': 'serve as', 'object': 'catalyst for dialogue'}, {'subject': 'community', 'verb': 'forge', 'object': 'common path honoring scientific curiosity and traditions'}]\n",
      "Output JSON: [{'subject': 'dr. lila montrose', 'verb': 'represent', 'object': 'tension between modern scientific inquiry and traditional cultural practices'}, {'subject': 'mr. edmund blackwell', 'verb': 'represent', 'object': 'tension between modern scientific inquiry and traditional cultural practices'}, {'subject': 'dr. lila montrose', 'verb': 'approach', 'object': 'eclipse with focus on scientific education and understanding'}, {'subject': 'dr. lila montrose', 'verb': 'emphasize', 'object': 'mechanics of eclipse and its psychological significance within modern framework'}, {'subject': 'mr. edmund blackwell', 'verb': 'view', 'object': 'eclipse through lens of tradition and culture'}, {'subject': 'mr. edmund blackwell', 'verb': 'advocate', 'object': 'revival of ancient rituals documented in manuscript'}, {'subject': 'ancient rituals', 'verb': 'be', 'object': \"essential to town's identity and historical unity\"}, {'subject': 'town of quillhaven', 'verb': 'propose', 'object': 'solution to conflict by organizing public forum'}, {'subject': 'public forum', 'verb': 'encourage', 'object': 'dialogue and collaboration between both perspectives'}, {'subject': 'debates and discussions', 'verb': 'conclude', 'object': 'eclipse could be catalyst for unity'}, {'subject': 'eclipse', 'verb': 'be', 'object': 'catalyst for unity'}, {'subject': 'unity', 'verb': 'bridge', 'object': 'modern scientific methods and respect for cultural heritage'}, {'subject': 'collaborative approach', 'verb': 'aim', 'object': 'honor both town’s scientific curiosity and deep-rooted traditions'}, {'subject': 'collaborative approach', 'verb': 'foster', 'object': 'common path forward'}]\n",
      "Similar Claims:\n",
      "Output Claim: dr. lila montrose represent tension between modern scientific inquiry and traditional cultural practices\n",
      "Similar Source Claim: {'subject': 'dr. lila montrose', 'verb': 'be', 'object': 'respected astrophysicist'} (Similarity: 0.6529564962466288)\n",
      "Similar Source Claim: {'subject': 'dr. lila montrose', 'verb': 'propose', 'object': 'public lectures and interactive exhibitions'} (Similarity: 0.6443945523882572)\n",
      "Similar Source Claim: {'subject': 'progressive wing', 'verb': 'advocate for', 'object': 'modern approach combining scientific exploration with cultural respect'} (Similarity: 0.4739170696292491)\n",
      "\n",
      "Output Claim: mr. edmund blackwell represent tension between modern scientific inquiry and traditional cultural practices\n",
      "Similar Source Claim: {'subject': 'mr. edmund blackwell', 'verb': 'argue', 'object': 'rituals fostered unity and prosperity'} (Similarity: 0.590336869508419)\n",
      "Similar Source Claim: {'subject': 'mr. edmund blackwell', 'verb': 'uncover', 'object': 'ancient manuscript'} (Similarity: 0.5885096666407457)\n",
      "Similar Source Claim: {'subject': 'progressive wing', 'verb': 'advocate for', 'object': 'modern approach combining scientific exploration with cultural respect'} (Similarity: 0.512100975652236)\n",
      "\n",
      "Output Claim: dr. lila montrose approach eclipse with focus on scientific education and understanding\n",
      "Similar Source Claim: {'subject': 'dr. lila montrose', 'verb': 'be', 'object': 'respected astrophysicist'} (Similarity: 0.6678520620954316)\n",
      "Similar Source Claim: {'subject': 'dr. lila montrose', 'verb': 'propose', 'object': 'public lectures and interactive exhibitions'} (Similarity: 0.6458854608596866)\n",
      "Similar Source Claim: {'subject': 'eclipse', 'verb': 'serve as', 'object': 'catalyst for dialogue'} (Similarity: 0.5288745373113016)\n",
      "\n",
      "Output Claim: dr. lila montrose emphasize mechanics of eclipse and its psychological significance within modern framework\n",
      "Similar Source Claim: {'subject': 'dr. lila montrose', 'verb': 'be', 'object': 'respected astrophysicist'} (Similarity: 0.5790416694783899)\n",
      "Similar Source Claim: {'subject': 'local legends', 'verb': 'suggest', 'object': 'eclipses influence human thought and communal harmony'} (Similarity: 0.5592945334577535)\n",
      "Similar Source Claim: {'subject': 'dr. lila montrose', 'verb': 'propose', 'object': 'public lectures and interactive exhibitions'} (Similarity: 0.5544529056722728)\n",
      "\n",
      "Output Claim: mr. edmund blackwell view eclipse through lens of tradition and culture\n",
      "Similar Source Claim: {'subject': 'mr. edmund blackwell', 'verb': 'argue', 'object': 'rituals fostered unity and prosperity'} (Similarity: 0.5461976346419624)\n",
      "Similar Source Claim: {'subject': 'eclipse', 'verb': 'serve as', 'object': 'catalyst for dialogue'} (Similarity: 0.5412885991622463)\n",
      "Similar Source Claim: {'subject': 'mr. edmund blackwell', 'verb': 'uncover', 'object': 'ancient manuscript'} (Similarity: 0.5337729942443706)\n",
      "\n",
      "Output Claim: mr. edmund blackwell advocate revival of ancient rituals documented in manuscript\n",
      "Similar Source Claim: {'subject': 'mr. edmund blackwell', 'verb': 'uncover', 'object': 'ancient manuscript'} (Similarity: 0.7537634893484197)\n",
      "Similar Source Claim: {'subject': 'mr. edmund blackwell', 'verb': 'argue', 'object': 'rituals fostered unity and prosperity'} (Similarity: 0.6774034652229516)\n",
      "Similar Source Claim: {'subject': 'conservative faction', 'verb': 'push for', 'object': 'return to traditional rituals'} (Similarity: 0.47826459816248856)\n",
      "\n",
      "Output Claim: ancient rituals be essential to town's identity and historical unity\n",
      "Similar Source Claim: {'subject': 'mr. edmund blackwell', 'verb': 'argue', 'object': 'rituals fostered unity and prosperity'} (Similarity: 0.5610134702392577)\n",
      "Similar Source Claim: {'subject': 'conservative faction', 'verb': 'push for', 'object': 'return to traditional rituals'} (Similarity: 0.5048252181428026)\n",
      "Similar Source Claim: {'subject': 'ancient manuscript', 'verb': 'detail', 'object': 'rituals and communal activities during eclipses'} (Similarity: 0.4936531750282871)\n",
      "\n",
      "Output Claim: town of quillhaven propose solution to conflict by organizing public forum\n",
      "Similar Source Claim: {'subject': 'town leaders', 'verb': 'organize', 'object': 'public forum'} (Similarity: 0.688155953401674)\n",
      "Similar Source Claim: {'subject': 'forum', 'verb': 'conclude with', 'object': 'proposal for collaboration'} (Similarity: 0.45499717412610824)\n",
      "Similar Source Claim: {'subject': 'quillhaven', 'verb': 'be renowned for', 'object': 'historic libraries and scholarly traditions'} (Similarity: 0.4291620506358711)\n",
      "\n",
      "Output Claim: public forum encourage dialogue and collaboration between both perspectives\n",
      "Similar Source Claim: {'subject': 'forum', 'verb': 'conclude with', 'object': 'proposal for collaboration'} (Similarity: 0.5793070844119762)\n",
      "Similar Source Claim: {'subject': 'eclipse', 'verb': 'serve as', 'object': 'catalyst for dialogue'} (Similarity: 0.5139146431774642)\n",
      "Similar Source Claim: {'subject': 'community', 'verb': 'forge', 'object': 'common path honoring scientific curiosity and traditions'} (Similarity: 0.4559604889889297)\n",
      "\n",
      "Output Claim: debates and discussions conclude eclipse could be catalyst for unity\n",
      "Similar Source Claim: {'subject': 'eclipse', 'verb': 'serve as', 'object': 'catalyst for dialogue'} (Similarity: 0.6803196011776804)\n",
      "Similar Source Claim: {'subject': 'local legends', 'verb': 'suggest', 'object': 'eclipses influence human thought and communal harmony'} (Similarity: 0.5597912797401693)\n",
      "Similar Source Claim: {'subject': 'mr. edmund blackwell', 'verb': 'argue', 'object': 'rituals fostered unity and prosperity'} (Similarity: 0.4202807025713646)\n",
      "\n",
      "Output Claim: eclipse be catalyst for unity\n",
      "Similar Source Claim: {'subject': 'eclipse', 'verb': 'serve as', 'object': 'catalyst for dialogue'} (Similarity: 0.7550666018035542)\n",
      "Similar Source Claim: {'subject': 'local legends', 'verb': 'suggest', 'object': 'eclipses influence human thought and communal harmony'} (Similarity: 0.5770978270230622)\n",
      "Similar Source Claim: {'subject': 'ancient manuscript', 'verb': 'detail', 'object': 'rituals and communal activities during eclipses'} (Similarity: 0.4157390682686538)\n",
      "\n",
      "Output Claim: unity bridge modern scientific methods and respect for cultural heritage\n",
      "Similar Source Claim: {'subject': 'community', 'verb': 'forge', 'object': 'common path honoring scientific curiosity and traditions'} (Similarity: 0.5683944362481084)\n",
      "Similar Source Claim: {'subject': 'progressive wing', 'verb': 'advocate for', 'object': 'modern approach combining scientific exploration with cultural respect'} (Similarity: 0.5153692746055104)\n",
      "Similar Source Claim: {'subject': 'forum', 'verb': 'conclude with', 'object': 'proposal for collaboration'} (Similarity: 0.35590642641514736)\n",
      "\n",
      "Output Claim: collaborative approach aim honor both town’s scientific curiosity and deep-rooted traditions\n",
      "Similar Source Claim: {'subject': 'community', 'verb': 'forge', 'object': 'common path honoring scientific curiosity and traditions'} (Similarity: 0.6809683625131272)\n",
      "Similar Source Claim: {'subject': 'progressive wing', 'verb': 'advocate for', 'object': 'modern approach combining scientific exploration with cultural respect'} (Similarity: 0.4769855641927776)\n",
      "Similar Source Claim: {'subject': 'forum', 'verb': 'conclude with', 'object': 'proposal for collaboration'} (Similarity: 0.4629631275240289)\n",
      "\n",
      "Output Claim: collaborative approach foster common path forward\n",
      "Similar Source Claim: {'subject': 'forum', 'verb': 'conclude with', 'object': 'proposal for collaboration'} (Similarity: 0.5522291575987667)\n",
      "Similar Source Claim: {'subject': 'community', 'verb': 'forge', 'object': 'common path honoring scientific curiosity and traditions'} (Similarity: 0.5155688398998368)\n",
      "Similar Source Claim: {'subject': 'progressive wing', 'verb': 'advocate for', 'object': 'modern approach combining scientific exploration with cultural respect'} (Similarity: 0.4079795183002812)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RAG prompt question-answering examples\n",
    "\n",
    "\n",
    "\n",
    "def ask_question(question: str, context: str, model=\"gpt-4-turbo\"):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant specialized in answering questions based on a given context. Your task is to provide accurate and concise answers to the questions asked. If the answer is not present in the context, you should respond with 'The answer is not present in the given context.'\"},\n",
    "            {\"role\": \"system\", \"content\": \"Context: \" + context},\n",
    "            {\"role\": \"user\", \"content\": f\"Question: {question}\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if completion.choices:\n",
    "        response_message = str(completion.choices[0].message.content)\n",
    "        return response_message\n",
    "    else:\n",
    "        print(\"No response received.\")\n",
    "        return None\n",
    "    \n",
    "# Example context and questions\n",
    "context = \"\"\"\n",
    "\n",
    "In the town of Quillhaven—a community renowned for its historic libraries and scholarly traditions—a rare astronomical event was predicted to occur for the first time in over a century. The event, a total solar eclipse, was shrouded in both scientific intrigue and centuries-old folklore. Local legends, drawing on influences from ancient Greek philosophy to indigenous spiritual practices, suggested that eclipses held the power to influence human thought and communal harmony.\n",
    "\n",
    "At the heart of the community’s preparations was Dr. Lila Montrose, a respected astrophysicist whose career had been dedicated to unraveling the mysteries of cosmic events. Dr. Montrose saw the eclipse as an opportunity to blend modern scientific inquiry with the town’s rich cultural heritage. She proposed a series of public lectures and interactive exhibitions designed to educate residents on the mechanics of the eclipse, while also acknowledging its historical and psychological significance. Her balanced approach aimed to respect both empirical evidence and the symbolic narratives that had long captivated the community.\n",
    "\n",
    "Meanwhile, Mr. Edmund Blackwell, the town’s dedicated historian, uncovered an ancient manuscript in the dusty archives of Quillhaven’s old library. The manuscript, penned in a mix of archaic English and Latin, detailed elaborate rituals and communal activities that had been performed during similar eclipses in bygone eras. Blackwell argued that these practices were more than mere superstition—they were intrinsic to the town’s identity and had once fostered unity and prosperity. His findings ignited a fervent debate about whether these ancient rituals should be revived as a way to reconnect with Quillhaven’s storied past.\n",
    "\n",
    "This emerging debate quickly divided the community into two factions. The progressive wing, led by Dr. Montrose, advocated for a balanced, modern approach that combined scientific exploration with cultural respect. In contrast, the conservative faction, inspired by Mr. Blackwell’s manuscript, pushed for a return to the traditional rituals that they believed had been the cornerstone of the town’s former unity and success. As the day of the eclipse drew near, these conflicting views not only highlighted an ideological rift but also symbolized a broader struggle between embracing modernity and preserving historical identity.\n",
    "\n",
    "In a final effort to bridge these divergent perspectives, town leaders organized a public forum. The forum featured spirited debates and passionate speeches, ultimately concluding with a proposal for collaboration. Both factions agreed that the eclipse could serve as a catalyst for dialogue, urging the community to forge a common path that honored both its scientific curiosity and its deep-rooted traditions.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "question = \"Explain how the contrasting views of Dr. Lila Montrose and Mr. Edmund Blackwell regarding the upcoming eclipse illustrate the broader tension between modern scientific inquiry and traditional cultural practices. What solution did the town of Quillhaven ultimately propose to address this conflict?\"\n",
    "\n",
    "# Get the answer to the question\n",
    "answer = ask_question(question, context)\n",
    "print(\"Answer:\", answer)\n",
    "\n",
    "source_json = extract_information(context)\n",
    "output_json = extract_information(answer)\n",
    "\n",
    "print(\"Source JSON:\", source_json)\n",
    "print(\"Output JSON:\", output_json)\n",
    "\n",
    "client_embed = OpenAI(api_key=os.getenv(\"EMBEDDING_API_KEY\"), base_url=os.getenv(\"EMBEDDING_BASE_URL\"))\n",
    "# Find semantically similar claims out of source and output JSON: \"convert these back to text by s-v-o format and compare them\", for each claim in output_json, find the two most similar claims in source_json\n",
    "def find_similar_claims(source_json, output_json):\n",
    "    source_graphs = []\n",
    "    output_graphs = []\n",
    "    for entry in source_json:\n",
    "        source_graphs.append(f\"{entry['subject']} {entry['verb']} {entry['object']}\")\n",
    "    for entry in output_json:\n",
    "        output_graphs.append(f\"{entry['subject']} {entry['verb']} {entry['object']}\")\n",
    "\n",
    "    # create embeddings for source and output graphs\n",
    "    source_embeddings = client_embed.embeddings.create(input=source_graphs, model=\"text-embedding-3-small\")\n",
    "    output_embeddings = client_embed.embeddings.create(input=output_graphs, model=\"text-embedding-3-small\")\n",
    "    # print(\"Source embeddings:\", source_embeddings)\n",
    "    similar_claims = {}\n",
    "\n",
    "    for i, output_entry in enumerate(output_json):\n",
    "        output_embedding = output_embeddings.data[i].embedding  \n",
    "        similarities = []\n",
    "        for j, source_entry in enumerate(source_json):\n",
    "            source_embedding = source_embeddings.data[j].embedding\n",
    "            # Calculate cosine similarity between embeddings\n",
    "            similarity = np.dot(output_embedding, source_embedding) / (np.linalg.norm(output_embedding) * np.linalg.norm(source_embedding))\n",
    "            similarities.append((source_entry, similarity))\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        # print(similarities)\n",
    "        output_entry_string = f\"{output_entry['subject']} {output_entry['verb']} {output_entry['object']}\"\n",
    "        similar_claims[output_entry_string] = similarities[:3]\n",
    "\n",
    "    return similar_claims\n",
    "\n",
    "similar_claims = find_similar_claims(source_json, output_json)\n",
    "\n",
    "print(\"Similar Claims:\")\n",
    "for output_entry, source_entries in similar_claims.items():\n",
    "    print(f\"Output Claim: {output_entry}\")\n",
    "    for source_entry, similarity in source_entries:\n",
    "        print(f\"Similar Source Claim: {source_entry} (Similarity: {similarity})\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: dr. lila montrose be respected astrophysicist;dr. lila montrose propose public lectures and interactive exhibitions;progressive wing advocate for modern approach combining scientific exploration with cultural respect\n",
      "Output: dr. lila montrose represent tension between modern scientific inquiry and traditional cultural practices\n",
      "\n",
      "Input: mr. edmund blackwell argue rituals fostered unity and prosperity;mr. edmund blackwell uncover ancient manuscript;progressive wing advocate for modern approach combining scientific exploration with cultural respect\n",
      "Output: mr. edmund blackwell represent tension between modern scientific inquiry and traditional cultural practices\n",
      "\n",
      "Input: dr. lila montrose be respected astrophysicist;dr. lila montrose propose public lectures and interactive exhibitions;eclipse serve as catalyst for dialogue\n",
      "Output: dr. lila montrose approach eclipse with focus on scientific education and understanding\n",
      "\n",
      "Input: dr. lila montrose be respected astrophysicist;local legends suggest eclipses influence human thought and communal harmony;dr. lila montrose propose public lectures and interactive exhibitions\n",
      "Output: dr. lila montrose emphasize mechanics of eclipse and its psychological significance within modern framework\n",
      "\n",
      "Input: mr. edmund blackwell argue rituals fostered unity and prosperity;eclipse serve as catalyst for dialogue;mr. edmund blackwell uncover ancient manuscript\n",
      "Output: mr. edmund blackwell view eclipse through lens of tradition and culture\n",
      "\n",
      "Input: mr. edmund blackwell uncover ancient manuscript;mr. edmund blackwell argue rituals fostered unity and prosperity;conservative faction push for return to traditional rituals\n",
      "Output: mr. edmund blackwell advocate revival of ancient rituals documented in manuscript\n",
      "\n",
      "Input: mr. edmund blackwell argue rituals fostered unity and prosperity;conservative faction push for return to traditional rituals;ancient manuscript detail rituals and communal activities during eclipses\n",
      "Output: ancient rituals be essential to town's identity and historical unity\n",
      "\n",
      "Input: town leaders organize public forum;forum conclude with proposal for collaboration;quillhaven be renowned for historic libraries and scholarly traditions\n",
      "Output: town of quillhaven propose solution to conflict by organizing public forum\n",
      "\n",
      "Input: forum conclude with proposal for collaboration;eclipse serve as catalyst for dialogue;community forge common path honoring scientific curiosity and traditions\n",
      "Output: public forum encourage dialogue and collaboration between both perspectives\n",
      "\n",
      "Input: eclipse serve as catalyst for dialogue;local legends suggest eclipses influence human thought and communal harmony;mr. edmund blackwell argue rituals fostered unity and prosperity\n",
      "Output: debates and discussions conclude eclipse could be catalyst for unity\n",
      "\n",
      "Input: eclipse serve as catalyst for dialogue;local legends suggest eclipses influence human thought and communal harmony;ancient manuscript detail rituals and communal activities during eclipses\n",
      "Output: eclipse be catalyst for unity\n",
      "\n",
      "Input: community forge common path honoring scientific curiosity and traditions;progressive wing advocate for modern approach combining scientific exploration with cultural respect;forum conclude with proposal for collaboration\n",
      "Output: unity bridge modern scientific methods and respect for cultural heritage\n",
      "\n",
      "Input: community forge common path honoring scientific curiosity and traditions;progressive wing advocate for modern approach combining scientific exploration with cultural respect;forum conclude with proposal for collaboration\n",
      "Output: collaborative approach aim honor both town’s scientific curiosity and deep-rooted traditions\n",
      "\n",
      "Input: forum conclude with proposal for collaboration;community forge common path honoring scientific curiosity and traditions;progressive wing advocate for modern approach combining scientific exploration with cultural respect\n",
      "Output: collaborative approach foster common path forward\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type HHEMv2Config to instantiate a model of type HHEMv2. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Determine if the hypothesis is true given the premise?\n",
      "\n",
      "Premise: dr. lila montrose be respected astrophysicist;dr. lila montrose propose public lectures and interactive exhibitions;progressive wing advocate for modern approach combining scientific exploration with cultural respect\n",
      "\n",
      "Hypothesis: dr. lila montrose represent tension between modern scientific inquiry and traditional cultural practices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type HHEMv2Config to instantiate a model of type HHEMv2. This is not supported for all configurations of models and can yield errors.\n",
      "You are using a model of type HHEMv2Config to instantiate a model of type HHEMv2. This is not supported for all configurations of models and can yield errors.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10602811723947525, 0.20501841604709625, 0.017742838710546494, 0.101949542760849, 0.43366050720214844, 0.7054314613342285, 0.2762347459793091, 0.1577477604150772, 0.3232259452342987, 0.9549278020858765, 0.47753217816352844, 0.44192075729370117, 0.04230152815580368, 0.884939432144165]\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login  \n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "\n",
    "login(token=os.getenv(\"HUGGINGFACE_TOKEN\"))\n",
    "# Generate pairs from similar claims\n",
    "claim_pairs = []\n",
    "for output_entry, source_entries in similar_claims.items():\n",
    "    source_claims = [f\"{source_entry['subject']} {source_entry['verb']} {source_entry['object']}\" for source_entry, _ in source_entries]\n",
    "    source_claims = \";\".join(source_claims)\n",
    "    claim_pairs.append((source_claims, output_entry))\n",
    "\n",
    "for pair in claim_pairs:\n",
    "    # Print the pairs in a beautiful format\n",
    "    print(\"Input:\", pair[0])\n",
    "    print(\"Output:\", pair[1])\n",
    "    print()\n",
    "\n",
    "# Step 1: Load the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained('vectara/hallucination_evaluation_model', trust_remote_code=True)\n",
    "\n",
    "# Step 2: Evaluate the hallucination model\n",
    "# Prompt the pairs\n",
    "prompt = \"<pad> Determine if the hypothesis is true given the premise?\\n\\nPremise: {text1}\\n\\nHypothesis: {text2}\"\n",
    "input_pairs = [prompt.format(text1=pair[0], text2=pair[1]) for pair in claim_pairs]\n",
    "print(input_pairs[0])\n",
    "\n",
    "# Use text-classification pipeline to predict\n",
    "classifier = pipeline(\n",
    "            \"text-classification\",\n",
    "            model='vectara/hallucination_evaluation_model',\n",
    "            tokenizer=AutoTokenizer.from_pretrained('google/flan-t5-base'),\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "full_scores = classifier(input_pairs, top_k=None) # List[List[Dict[str, float]]]\n",
    "\n",
    "# Optional: Extract the scores for the 'consistent' label\n",
    "simple_scores = [score_dict['score'] for score_for_both_labels in full_scores for score_dict in score_for_both_labels if score_dict['label'] == 'consistent']\n",
    "\n",
    "print(simple_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machine_summaries</th>\n",
       "      <th>human_summaries</th>\n",
       "      <th>relevance</th>\n",
       "      <th>coherence</th>\n",
       "      <th>fluency</th>\n",
       "      <th>consistency</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[donald sterling , nba team last year . sterli...</td>\n",
       "      <td>[V. Stiviano must pay back $2.6 million in gif...</td>\n",
       "      <td>[1.6666666666666667, 1.6666666666666667, 2.333...</td>\n",
       "      <td>[1.3333333333333333, 3.0, 1.0, 2.6666666666666...</td>\n",
       "      <td>[1.0, 4.666666666666667, 4.333333333333333, 4....</td>\n",
       "      <td>[1.0, 2.3333333333333335, 4.666666666666667, 5...</td>\n",
       "      <td>(CNN)Donald Sterling's racist remarks cost him...</td>\n",
       "      <td>cnn-test-404f859482d47c127868964a9a39d1a7645dd2e9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[north pacific gray whale has earned a spot in...</td>\n",
       "      <td>[The whale, Varvara, swam a round trip from Ru...</td>\n",
       "      <td>[2.3333333333333335, 4.666666666666667, 3.6666...</td>\n",
       "      <td>[1.3333333333333333, 4.666666666666667, 3.6666...</td>\n",
       "      <td>[1.0, 5.0, 4.666666666666667, 3.66666666666666...</td>\n",
       "      <td>[1.3333333333333333, 5.0, 5.0, 4.3333333333333...</td>\n",
       "      <td>(CNN)A North Pacific gray whale has earned a s...</td>\n",
       "      <td>cnn-test-4761dc6d8bdf56b9ada97104113dd1bcf4aed3f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[russian fighter jet intercepted a u.s. reconn...</td>\n",
       "      <td>[The incident occurred on April 7 north of Pol...</td>\n",
       "      <td>[4.0, 4.0, 4.0, 3.3333333333333335, 3.33333333...</td>\n",
       "      <td>[3.3333333333333335, 4.333333333333333, 1.6666...</td>\n",
       "      <td>[3.6666666666666665, 4.333333333333333, 5.0, 4...</td>\n",
       "      <td>[5.0, 5.0, 4.666666666666667, 5.0, 5.0, 5.0, 5...</td>\n",
       "      <td>(CNN)After a Russian fighter jet intercepted a...</td>\n",
       "      <td>cnn-test-5139ccfabee55ddb83e7937f5802c0a67aee8975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[michael barnett captured the fire on intersta...</td>\n",
       "      <td>[Country band Lady Antebellum's bus caught fir...</td>\n",
       "      <td>[2.0, 3.0, 2.6666666666666665, 3.3333333333333...</td>\n",
       "      <td>[2.0, 3.0, 2.6666666666666665, 3.3333333333333...</td>\n",
       "      <td>[2.6666666666666665, 5.0, 5.0, 5.0, 5.0, 5.0, ...</td>\n",
       "      <td>[2.3333333333333335, 5.0, 5.0, 5.0, 5.0, 5.0, ...</td>\n",
       "      <td>(CNN)Lady Antebellum singer Hillary Scott's to...</td>\n",
       "      <td>cnn-test-88c2481234e763c9bbc68d0ab1be1d2375c1349a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[deep reddish color caught seattle native tim ...</td>\n",
       "      <td>[Smoke from massive fires in Siberia created f...</td>\n",
       "      <td>[1.6666666666666667, 3.6666666666666665, 3.333...</td>\n",
       "      <td>[1.6666666666666667, 3.6666666666666665, 1.666...</td>\n",
       "      <td>[5.0, 5.0, 5.0, 5.0, 4.666666666666667, 5.0, 5...</td>\n",
       "      <td>[2.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...</td>\n",
       "      <td>(CNN)A fiery sunset greeted people in Washingt...</td>\n",
       "      <td>cnn-test-a02e362c5b8f049848ce718b37b96117485461cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[chelsea have made an offer for fc tokyo 's du...</td>\n",
       "      <td>[Naoki Ogane says that Chelsea have made an of...</td>\n",
       "      <td>[3.0, 4.333333333333333, 4.0, 4.0, 4.333333333...</td>\n",
       "      <td>[2.0, 4.0, 4.333333333333333, 3.66666666666666...</td>\n",
       "      <td>[3.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...</td>\n",
       "      <td>[2.0, 5.0, 5.0, 4.333333333333333, 5.0, 5.0, 5...</td>\n",
       "      <td>Chelsea have made an offer for FC Tokyo's 22-y...</td>\n",
       "      <td>dm-test-f26d8400ae49b90d109c165d0f44b8f6ca253c08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[christopher lawler said he was pinned to a ch...</td>\n",
       "      <td>[Christopher Lawler claims he was pinned to a ...</td>\n",
       "      <td>[5.0, 4.333333333333333, 4.333333333333333, 4....</td>\n",
       "      <td>[3.0, 4.333333333333333, 3.6666666666666665, 4...</td>\n",
       "      <td>[5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 3.0, ...</td>\n",
       "      <td>[5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 1.333...</td>\n",
       "      <td>Police are investigating claims by a former ro...</td>\n",
       "      <td>dm-test-f37fd6e9b6cc18a7132568e307ef3b130931e809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[eden hazard scored a 1-0 lead against manches...</td>\n",
       "      <td>[Eden Hazard scored the opening goal for Chels...</td>\n",
       "      <td>[3.3333333333333335, 3.3333333333333335, 3.666...</td>\n",
       "      <td>[2.0, 2.0, 1.6666666666666667, 1.6666666666666...</td>\n",
       "      <td>[3.3333333333333335, 4.666666666666667, 5.0, 5...</td>\n",
       "      <td>[1.6666666666666667, 5.0, 5.0, 5.0, 4.0, 5.0, ...</td>\n",
       "      <td>After Chelsea forward Eden Hazard had scored g...</td>\n",
       "      <td>dm-test-f468efac7b3c54f8c42c2c81dff108c52ebe0d7d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[evangelos patoulidis is regarded as one of th...</td>\n",
       "      <td>[Evangelos Patoulidis also attracted interest ...</td>\n",
       "      <td>[3.6666666666666665, 4.333333333333333, 4.0, 4...</td>\n",
       "      <td>[2.6666666666666665, 5.0, 5.0, 4.3333333333333...</td>\n",
       "      <td>[4.333333333333333, 5.0, 5.0, 4.66666666666666...</td>\n",
       "      <td>[5.0, 5.0, 5.0, 5.0, 5.0, 4.666666666666667, 5...</td>\n",
       "      <td>Manchester City are keen to sign Anderlecht te...</td>\n",
       "      <td>dm-test-f5fead94ee884800e84a212cc0edc78b11c4ba9f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[woman named only as gemma , has two children ...</td>\n",
       "      <td>[Gemma, 23, has left her children to be raised...</td>\n",
       "      <td>[4.666666666666667, 4.0, 4.333333333333333, 4....</td>\n",
       "      <td>[3.3333333333333335, 2.3333333333333335, 2.666...</td>\n",
       "      <td>[4.0, 5.0, 5.0, 5.0, 5.0, 4.333333333333333, 5...</td>\n",
       "      <td>[5.0, 2.0, 5.0, 4.666666666666667, 5.0, 5.0, 5...</td>\n",
       "      <td>A 23-year-old mother-of-two is at risk of bein...</td>\n",
       "      <td>dm-test-fadabe346fe95d33eee71299e6596754768f5246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    machine_summaries  \\\n",
       "0   [donald sterling , nba team last year . sterli...   \n",
       "1   [north pacific gray whale has earned a spot in...   \n",
       "2   [russian fighter jet intercepted a u.s. reconn...   \n",
       "3   [michael barnett captured the fire on intersta...   \n",
       "4   [deep reddish color caught seattle native tim ...   \n",
       "..                                                ...   \n",
       "95  [chelsea have made an offer for fc tokyo 's du...   \n",
       "96  [christopher lawler said he was pinned to a ch...   \n",
       "97  [eden hazard scored a 1-0 lead against manches...   \n",
       "98  [evangelos patoulidis is regarded as one of th...   \n",
       "99  [woman named only as gemma , has two children ...   \n",
       "\n",
       "                                      human_summaries  \\\n",
       "0   [V. Stiviano must pay back $2.6 million in gif...   \n",
       "1   [The whale, Varvara, swam a round trip from Ru...   \n",
       "2   [The incident occurred on April 7 north of Pol...   \n",
       "3   [Country band Lady Antebellum's bus caught fir...   \n",
       "4   [Smoke from massive fires in Siberia created f...   \n",
       "..                                                ...   \n",
       "95  [Naoki Ogane says that Chelsea have made an of...   \n",
       "96  [Christopher Lawler claims he was pinned to a ...   \n",
       "97  [Eden Hazard scored the opening goal for Chels...   \n",
       "98  [Evangelos Patoulidis also attracted interest ...   \n",
       "99  [Gemma, 23, has left her children to be raised...   \n",
       "\n",
       "                                            relevance  \\\n",
       "0   [1.6666666666666667, 1.6666666666666667, 2.333...   \n",
       "1   [2.3333333333333335, 4.666666666666667, 3.6666...   \n",
       "2   [4.0, 4.0, 4.0, 3.3333333333333335, 3.33333333...   \n",
       "3   [2.0, 3.0, 2.6666666666666665, 3.3333333333333...   \n",
       "4   [1.6666666666666667, 3.6666666666666665, 3.333...   \n",
       "..                                                ...   \n",
       "95  [3.0, 4.333333333333333, 4.0, 4.0, 4.333333333...   \n",
       "96  [5.0, 4.333333333333333, 4.333333333333333, 4....   \n",
       "97  [3.3333333333333335, 3.3333333333333335, 3.666...   \n",
       "98  [3.6666666666666665, 4.333333333333333, 4.0, 4...   \n",
       "99  [4.666666666666667, 4.0, 4.333333333333333, 4....   \n",
       "\n",
       "                                            coherence  \\\n",
       "0   [1.3333333333333333, 3.0, 1.0, 2.6666666666666...   \n",
       "1   [1.3333333333333333, 4.666666666666667, 3.6666...   \n",
       "2   [3.3333333333333335, 4.333333333333333, 1.6666...   \n",
       "3   [2.0, 3.0, 2.6666666666666665, 3.3333333333333...   \n",
       "4   [1.6666666666666667, 3.6666666666666665, 1.666...   \n",
       "..                                                ...   \n",
       "95  [2.0, 4.0, 4.333333333333333, 3.66666666666666...   \n",
       "96  [3.0, 4.333333333333333, 3.6666666666666665, 4...   \n",
       "97  [2.0, 2.0, 1.6666666666666667, 1.6666666666666...   \n",
       "98  [2.6666666666666665, 5.0, 5.0, 4.3333333333333...   \n",
       "99  [3.3333333333333335, 2.3333333333333335, 2.666...   \n",
       "\n",
       "                                              fluency  \\\n",
       "0   [1.0, 4.666666666666667, 4.333333333333333, 4....   \n",
       "1   [1.0, 5.0, 4.666666666666667, 3.66666666666666...   \n",
       "2   [3.6666666666666665, 4.333333333333333, 5.0, 4...   \n",
       "3   [2.6666666666666665, 5.0, 5.0, 5.0, 5.0, 5.0, ...   \n",
       "4   [5.0, 5.0, 5.0, 5.0, 4.666666666666667, 5.0, 5...   \n",
       "..                                                ...   \n",
       "95  [3.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...   \n",
       "96  [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 3.0, ...   \n",
       "97  [3.3333333333333335, 4.666666666666667, 5.0, 5...   \n",
       "98  [4.333333333333333, 5.0, 5.0, 4.66666666666666...   \n",
       "99  [4.0, 5.0, 5.0, 5.0, 5.0, 4.333333333333333, 5...   \n",
       "\n",
       "                                          consistency  \\\n",
       "0   [1.0, 2.3333333333333335, 4.666666666666667, 5...   \n",
       "1   [1.3333333333333333, 5.0, 5.0, 4.3333333333333...   \n",
       "2   [5.0, 5.0, 4.666666666666667, 5.0, 5.0, 5.0, 5...   \n",
       "3   [2.3333333333333335, 5.0, 5.0, 5.0, 5.0, 5.0, ...   \n",
       "4   [2.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...   \n",
       "..                                                ...   \n",
       "95  [2.0, 5.0, 5.0, 4.333333333333333, 5.0, 5.0, 5...   \n",
       "96  [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 1.333...   \n",
       "97  [1.6666666666666667, 5.0, 5.0, 5.0, 4.0, 5.0, ...   \n",
       "98  [5.0, 5.0, 5.0, 5.0, 5.0, 4.666666666666667, 5...   \n",
       "99  [5.0, 2.0, 5.0, 4.666666666666667, 5.0, 5.0, 5...   \n",
       "\n",
       "                                                 text  \\\n",
       "0   (CNN)Donald Sterling's racist remarks cost him...   \n",
       "1   (CNN)A North Pacific gray whale has earned a s...   \n",
       "2   (CNN)After a Russian fighter jet intercepted a...   \n",
       "3   (CNN)Lady Antebellum singer Hillary Scott's to...   \n",
       "4   (CNN)A fiery sunset greeted people in Washingt...   \n",
       "..                                                ...   \n",
       "95  Chelsea have made an offer for FC Tokyo's 22-y...   \n",
       "96  Police are investigating claims by a former ro...   \n",
       "97  After Chelsea forward Eden Hazard had scored g...   \n",
       "98  Manchester City are keen to sign Anderlecht te...   \n",
       "99  A 23-year-old mother-of-two is at risk of bein...   \n",
       "\n",
       "                                                   id  \n",
       "0   cnn-test-404f859482d47c127868964a9a39d1a7645dd2e9  \n",
       "1   cnn-test-4761dc6d8bdf56b9ada97104113dd1bcf4aed3f1  \n",
       "2   cnn-test-5139ccfabee55ddb83e7937f5802c0a67aee8975  \n",
       "3   cnn-test-88c2481234e763c9bbc68d0ab1be1d2375c1349a  \n",
       "4   cnn-test-a02e362c5b8f049848ce718b37b96117485461cf  \n",
       "..                                                ...  \n",
       "95   dm-test-f26d8400ae49b90d109c165d0f44b8f6ca253c08  \n",
       "96   dm-test-f37fd6e9b6cc18a7132568e307ef3b130931e809  \n",
       "97   dm-test-f468efac7b3c54f8c42c2c81dff108c52ebe0d7d  \n",
       "98   dm-test-f5fead94ee884800e84a212cc0edc78b11c4ba9f  \n",
       "99   dm-test-fadabe346fe95d33eee71299e6596754768f5246  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "df = pd.read_parquet(\"hf://datasets/mteb/summeval/data/test-00000-of-00001-35901af5f6649399.parquet\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>machine_summary</th>\n",
       "      <th>consistency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN)Donald Sterling's racist remarks cost him...</td>\n",
       "      <td>donald sterling , nba team last year . sterlin...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN)Donald Sterling's racist remarks cost him...</td>\n",
       "      <td>donald sterling accused stiviano of targeting ...</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(CNN)Donald Sterling's racist remarks cost him...</td>\n",
       "      <td>a los angeles judge has ordered v. stiviano to...</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(CNN)Donald Sterling's racist remarks cost him...</td>\n",
       "      <td>donald sterling 's wife sued stiviano of targe...</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(CNN)Donald Sterling's racist remarks cost him...</td>\n",
       "      <td>donald sterling 's racist remarks cost him an ...</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>A 23-year-old mother-of-two is at risk of bein...</td>\n",
       "      <td>a 23-year-old mother-of-two is at risk of bein...</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>A 23-year-old mother-of-two is at risk of bein...</td>\n",
       "      <td>Gemma , 23 , has two children under five by tw...</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>A 23-year-old mother-of-two is at risk of bein...</td>\n",
       "      <td>gemma , named only as gemma , has two children...</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>A 23-year-old mother-of-two is at risk of bein...</td>\n",
       "      <td>the woman , named only as gemma , has two chil...</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>A 23-year-old mother-of-two is at risk of bein...</td>\n",
       "      <td>the woman has two children under five by two d...</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     (CNN)Donald Sterling's racist remarks cost him...   \n",
       "1     (CNN)Donald Sterling's racist remarks cost him...   \n",
       "2     (CNN)Donald Sterling's racist remarks cost him...   \n",
       "3     (CNN)Donald Sterling's racist remarks cost him...   \n",
       "4     (CNN)Donald Sterling's racist remarks cost him...   \n",
       "...                                                 ...   \n",
       "1595  A 23-year-old mother-of-two is at risk of bein...   \n",
       "1596  A 23-year-old mother-of-two is at risk of bein...   \n",
       "1597  A 23-year-old mother-of-two is at risk of bein...   \n",
       "1598  A 23-year-old mother-of-two is at risk of bein...   \n",
       "1599  A 23-year-old mother-of-two is at risk of bein...   \n",
       "\n",
       "                                        machine_summary  consistency  \n",
       "0     donald sterling , nba team last year . sterlin...     1.000000  \n",
       "1     donald sterling accused stiviano of targeting ...     2.333333  \n",
       "2     a los angeles judge has ordered v. stiviano to...     4.666667  \n",
       "3     donald sterling 's wife sued stiviano of targe...     5.000000  \n",
       "4     donald sterling 's racist remarks cost him an ...     5.000000  \n",
       "...                                                 ...          ...  \n",
       "1595  a 23-year-old mother-of-two is at risk of bein...     5.000000  \n",
       "1596  Gemma , 23 , has two children under five by tw...     5.000000  \n",
       "1597  gemma , named only as gemma , has two children...     5.000000  \n",
       "1598  the woman , named only as gemma , has two chil...     5.000000  \n",
       "1599  the woman has two children under five by two d...     5.000000  \n",
       "\n",
       "[1600 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This dataset contains machine_summaries, human_summaries, text and consistency. Apart from the text, all other columns are lists of strings. The text column contains the original text, while the machine_summaries and human_summaries columns contain the machine-generated and human-written summaries, respectively. The consistency column contains a list of consistency scores for each summary.\n",
    "# Build a new dataframe, where each row contains the text, machine_summary, human_summary, and consistency score for a single summary. This will make it easier to work with the data.\n",
    "# Create a new dataframe with the desired columns\n",
    "\n",
    "# Verify that for each row the lengths of machine_summaries, human_summaries, and consistency are equal.\n",
    "\n",
    "\n",
    "\n",
    "# If it is expand the df\n",
    "df_expanded = pd.DataFrame({\n",
    "    'text': df['text'].repeat(df['machine_summaries'].str.len()).reset_index(drop=True),\n",
    "    'machine_summary': [summary for summaries in df['machine_summaries'] for summary in summaries],\n",
    "    # 'human_summary': [summary for summaries in df['human_summaries'] for summary in summaries],\n",
    "    'consistency': [score for scores in df['consistency'] for score in scores]\n",
    "})\n",
    "\n",
    "\n",
    "df_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1306\n",
      "0     294\n",
      "Name: count, dtype: int64\n",
      "Ratio of 1s to 0s: 4.44\n"
     ]
    }
   ],
   "source": [
    "# Convert the consistency column to a list of floats, and make it binary, where anything less than a 5 is a 0, and anything greater than or equal to a 5 is a 1.\n",
    "df_expanded['consistency'] = df_expanded['consistency'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "# Count the number of 1s and 0s in the consistency column\n",
    "consistency_counts = df_expanded['consistency'].apply(pd.Series).stack().value_counts()\n",
    "print(consistency_counts)\n",
    "# Find the ratio of 1s to 0s\n",
    "ratio = consistency_counts[1] / consistency_counts[0]\n",
    "print(f\"Ratio of 1s to 0s: {ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type HHEMv2Config to instantiate a model of type HHEMv2. This is not supported for all configurations of models and can yield errors.\n",
      "You are using a model of type HHEMv2Config to instantiate a model of type HHEMv2. This is not supported for all configurations of models and can yield errors.\n",
      "Device set to use mps:0\n",
      "  1%|          | 11/1600 [01:51<3:17:48,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 105/1600 [16:53<3:17:59,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 137/1600 [21:24<3:31:16,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 182/1600 [33:21<4:02:31, 10.26s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 183/1600 [33:27<3:27:35,  8.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 189/1600 [34:29<3:13:56,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 276/1600 [58:47<5:47:45, 15.76s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 317/1600 [1:10:26<4:24:14, 12.36s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 327/1600 [1:12:53<5:02:09, 14.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 522/1600 [2:25:05<11:45:32, 39.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] extract_information on summary failed: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 607/1600 [3:07:48<2:21:07,  8.53s/it] "
     ]
    }
   ],
   "source": [
    "import json\n",
    "from json import JSONDecodeError\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "# 1️⃣ One‐time model + tokenizer init\n",
    "_tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-base')\n",
    "_grapheval_clf = pipeline(\n",
    "    \"text-classification\",\n",
    "    model='vectara/hallucination_evaluation_model',\n",
    "    tokenizer=_tokenizer,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# 2️⃣ Prompt template & threshold\n",
    "_PROMPT = (\n",
    "    \"<pad> Determine if the hypothesis is true given the premise?\\n\\n\"\n",
    "    \"Premise: {premise}\\n\\n\"\n",
    "    \"Hypothesis: {hypothesis}\"\n",
    ")\n",
    "_THRESHOLD = 0.5\n",
    "\n",
    "# 3️⃣ Cache for extracted source JSON\n",
    "_source_cache: dict[str, dict] = {}\n",
    "\n",
    "def perform_grapheval(text: str, machine_output: str, threshold: float = _THRESHOLD) -> bool:\n",
    "    # — get or compute source_json (cached)\n",
    "    try:\n",
    "        if text not in _source_cache:\n",
    "            _source_cache[text] = extract_information(text)\n",
    "        source_json = _source_cache[text]\n",
    "    except JSONDecodeError as e:\n",
    "        print(f\"[Warning] extract_information on source failed: {e}\")\n",
    "        return False\n",
    "\n",
    "    # — always re-extract & compare for the summary\n",
    "    try:\n",
    "        output_json = extract_information(machine_output)\n",
    "    except JSONDecodeError as e:\n",
    "        print(f\"[Warning] extract_information on summary failed: {e}\")\n",
    "        return False\n",
    "\n",
    "    similar = find_similar_claims(source_json, output_json)\n",
    "    if not similar:\n",
    "        return True\n",
    "\n",
    "    # — build the prompts\n",
    "    prompts = [\n",
    "        _PROMPT.format(\n",
    "            premise=\";\".join(f\"{s['subject']} {s['verb']} {s['object']}\" for s, _ in sources),\n",
    "            hypothesis=hyp\n",
    "        )\n",
    "        for hyp, sources in similar.items()\n",
    "    ]\n",
    "\n",
    "    # — run the hallucination classifier\n",
    "    results = _grapheval_clf(prompts, top_k=None)\n",
    "    scores = [\n",
    "        entry['score']\n",
    "        for res in results\n",
    "        for entry in res\n",
    "        if entry.get('label', '').lower() == 'consistent'\n",
    "    ]\n",
    "\n",
    "    return all(score >= threshold for score in scores)\n",
    "\n",
    "# 4️⃣ Apply across your DataFrame with a safe wrapper\n",
    "tqdm.pandas()\n",
    "\n",
    "def safe_eval(row):\n",
    "    try:\n",
    "        return int(perform_grapheval(row['text'], row['machine_summary']))\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Row {row.name} failed evaluation: {e}\")\n",
    "        return -1\n",
    "\n",
    "df_expanded['grapheval_consistency'] = df_expanded.progress_apply(safe_eval, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the balanced accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "# Calculate the balanced accuracy score\n",
    "balanced_accuracy = balanced_accuracy_score(df_expanded['consistency'], df_expanded['grapheval_consistency'])\n",
    "print(f\"Balanced Accuracy Score: {balanced_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from json import JSONDecodeError\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "# 1️⃣ One‐time model + tokenizer init\n",
    "_tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-base')\n",
    "_grapheval_clf = pipeline(\n",
    "    \"text-classification\",\n",
    "    model='vectara/hallucination_evaluation_model',\n",
    "    tokenizer=_tokenizer,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# 2️⃣ Prompt template & threshold\n",
    "_PROMPT = (\n",
    "    \"<pad> Determine if the hypothesis is true given the premise?\\n\\n\"\n",
    "    \"Premise: {premise}\\n\\n\"\n",
    "    \"Hypothesis: {hypothesis}\"\n",
    ")\n",
    "_THRESHOLD = 0.5\n",
    "\n",
    "# 3️⃣ Cache for extracted source JSON - needs to be manager dict for multiprocessing\n",
    "_manager = mp.Manager()\n",
    "_source_cache = _manager.dict()\n",
    "\n",
    "def extract_information(text):\n",
    "    \"\"\"\n",
    "    Extract information from text to structured format.\n",
    "    This is a placeholder - replace with your actual implementation.\n",
    "    \"\"\"\n",
    "    # Placeholder - replace with your actual implementation\n",
    "    # This should return a structured representation of the text\n",
    "    return {\"claims\": [{\"subject\": \"example\", \"verb\": \"is\", \"object\": \"placeholder\"}]}\n",
    "\n",
    "def find_similar_claims(source_json, output_json):\n",
    "    \"\"\"\n",
    "    Find similar claims between source and output JSON.\n",
    "    This is a placeholder - replace with your actual implementation.\n",
    "    \"\"\"\n",
    "    # Placeholder - replace with your actual implementation\n",
    "    # This should return a dict mapping hypotheses to sources\n",
    "    return {\"example is placeholder\": [({\"subject\": \"example\", \"verb\": \"is\", \"object\": \"placeholder\"}, 1.0)]}\n",
    "\n",
    "def perform_grapheval(row, threshold=_THRESHOLD):\n",
    "    \"\"\"Evaluate a single row using the GraphEval approach\"\"\"\n",
    "    text = row['text']\n",
    "    machine_output = row['machine_summary']\n",
    "    \n",
    "    # — get or compute source_json (cached)\n",
    "    try:\n",
    "        # Need to handle multiprocessing cache differently\n",
    "        if text not in _source_cache:\n",
    "            with mp.Lock():\n",
    "                if text not in _source_cache:  # Check again to avoid race condition\n",
    "                    _source_cache[text] = extract_information(text)\n",
    "        source_json = _source_cache[text]\n",
    "    except JSONDecodeError as e:\n",
    "        print(f\"[Warning] extract_information on source failed: {e}\")\n",
    "        return -1\n",
    "\n",
    "    # — always re-extract & compare for the summary\n",
    "    try:\n",
    "        output_json = extract_information(machine_output)\n",
    "    except JSONDecodeError as e:\n",
    "        print(f\"[Warning] extract_information on summary failed: {e}\")\n",
    "        return -1\n",
    "\n",
    "    similar = find_similar_claims(source_json, output_json)\n",
    "    if not similar:\n",
    "        return 1  # True\n",
    "\n",
    "    # — build the prompts\n",
    "    prompts = [\n",
    "        _PROMPT.format(\n",
    "            premise=\";\".join(f\"{s['subject']} {s['verb']} {s['object']}\" for s, _ in sources),\n",
    "            hypothesis=hyp\n",
    "        )\n",
    "        for hyp, sources in similar.items()\n",
    "    ]\n",
    "\n",
    "    # — run the hallucination classifier\n",
    "    results = _grapheval_clf(prompts, top_k=None)\n",
    "    scores = [\n",
    "        entry['score']\n",
    "        for res in results\n",
    "        for entry in res\n",
    "        if entry.get('label', '').lower() == 'consistent'\n",
    "    ]\n",
    "\n",
    "    return int(all(score >= threshold for score in scores))\n",
    "\n",
    "def safe_eval(row):\n",
    "    \"\"\"Safely evaluate a row, catching any exceptions\"\"\"\n",
    "    try:\n",
    "        return perform_grapheval(row)\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Row {row.name} failed evaluation: {e}\")\n",
    "        return -1\n",
    "\n",
    "def process_chunk(df_chunk):\n",
    "    \"\"\"Process a chunk of the DataFrame\"\"\"\n",
    "    results = []\n",
    "    for _, row in df_chunk.iterrows():\n",
    "        results.append((row.name, safe_eval(row)))\n",
    "    return results\n",
    "\n",
    "def parallel_grapheval(df, num_processes=None):\n",
    "    \"\"\"\n",
    "    Apply GraphEval across DataFrame with parallel processing\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'text' and 'machine_summary' columns\n",
    "        num_processes: Number of processes to use (defaults to CPU count)\n",
    "    \n",
    "    Returns:\n",
    "        Series with evaluation results\n",
    "    \"\"\"\n",
    "    # Determine optimal number of processes\n",
    "    if num_processes is None:\n",
    "        num_processes = mp.cpu_count()\n",
    "    \n",
    "    # Split DataFrame into chunks\n",
    "    chunk_size = max(1, len(df) // num_processes)\n",
    "    chunks = [df.iloc[i:i+chunk_size] for i in range(0, len(df), chunk_size)]\n",
    "    \n",
    "    # Process chunks in parallel\n",
    "    print(f\"Processing {len(df)} rows with {num_processes} processes\")\n",
    "    with mp.Pool(processes=num_processes) as pool:\n",
    "        results = list(tqdm(\n",
    "            pool.imap(process_chunk, chunks),\n",
    "            total=len(chunks),\n",
    "            desc=\"Processing chunks\"\n",
    "        ))\n",
    "    \n",
    "    # Flatten results\n",
    "    flat_results = []\n",
    "    for chunk_result in results:\n",
    "        flat_results.extend(chunk_result)\n",
    "    \n",
    "    # Convert to Series\n",
    "    result_dict = dict(flat_results)\n",
    "    return df.index.map(lambda idx: result_dict.get(idx, -1))\n",
    "\n",
    "# 4️⃣ Apply across your DataFrame with parallel processing\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    # df_expanded['grapheval_consistency'] = parallel_grapheval(df_expanded)\n",
    "    \n",
    "    # For demonstration with a simple DataFrame\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Create a sample DataFrame\n",
    "    data = {\n",
    "        'text': ['This is a sample text.'] * 10,\n",
    "        'machine_summary': ['This is a summary.'] * 10\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Run parallel evaluation\n",
    "    result = parallel_grapheval(df)\n",
    "    \n",
    "    # Add results to DataFrame\n",
    "    df['grapheval_consistency'] = result\n",
    "    print(df)\n",
    "\n",
    "# For integrating with your existing code:\n",
    "df_expanded['grapheval_consistency'] = parallel_grapheval(df_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

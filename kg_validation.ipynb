{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in ./myenv/lib/python3.13/site-packages (3.4.2)\n",
      "Requirement already satisfied: matplotlib in ./myenv/lib/python3.13/site-packages (3.10.1)\n",
      "Requirement already satisfied: pyvis in ./myenv/lib/python3.13/site-packages (0.3.2)\n",
      "Requirement already satisfied: openai in ./myenv/lib/python3.13/site-packages (1.67.0)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./myenv/lib/python3.13/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./myenv/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./myenv/lib/python3.13/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./myenv/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in ./myenv/lib/python3.13/site-packages (from matplotlib) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./myenv/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./myenv/lib/python3.13/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./myenv/lib/python3.13/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./myenv/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: ipython>=5.3.0 in ./myenv/lib/python3.13/site-packages (from pyvis) (9.0.2)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in ./myenv/lib/python3.13/site-packages (from pyvis) (3.1.6)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in ./myenv/lib/python3.13/site-packages (from pyvis) (4.0.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./myenv/lib/python3.13/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./myenv/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./myenv/lib/python3.13/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./myenv/lib/python3.13/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./myenv/lib/python3.13/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in ./myenv/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./myenv/lib/python3.13/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./myenv/lib/python3.13/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in ./myenv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in ./myenv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in ./myenv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./myenv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: decorator in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (2.19.1)\n",
      "Requirement already satisfied: stack_data in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in ./myenv/lib/python3.13/site-packages (from ipython>=5.3.0->pyvis) (5.14.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./myenv/lib/python3.13/site-packages (from jinja2>=2.9.6->pyvis) (3.0.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./myenv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./myenv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in ./myenv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./myenv/lib/python3.13/site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./myenv/lib/python3.13/site-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./myenv/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./myenv/lib/python3.13/site-packages (from stack_data->ipython>=5.3.0->pyvis) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./myenv/lib/python3.13/site-packages (from stack_data->ipython>=5.3.0->pyvis) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./myenv/lib/python3.13/site-packages (from stack_data->ipython>=5.3.0->pyvis) (0.2.3)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install networkx matplotlib pyvis openai python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Define your API key securely\n",
    "# @ANISHA - Enter your OpenAI API key here\n",
    "# - If you don't have an API key, you can get one by signing up at https://platform.openai.com/signup\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "\n",
    "\n",
    "def extract_information(text: str):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",  # Use an appropriate model\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant specialized in extracting subjects, verbs, and objects from text for knowledge graph construction. Your task is to identify these entities, their attributes, and the relationships between them, and output them in a structured JSON format. IMPORTANT: Make sure that all pronouns are converted to nouns unless not possible. Any conjunctions should be treated as separate sentences. If a subject or object cannot be identified, label it as unidentified. Consider a verb as the connection between the subject and object, including prepositions (or both together) when relevant REMOVE over-wordiness where possible, like it doesn't have to be 'a boy named jack' as subject, it can be 'jack' as subject. If a subject or object cannot be identified, label it as unidentified. Keep everything lower case and present tense and try to keep the subject and object as a single word if possible.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Analyze the following text and identify subjects, verbs, and objects. For each sentence in the text, create one JSON object with the keys 'subject', 'verb', and 'object'. Only keep adjectives if they tend to act as subject or object. For example Jack is brave shall include brave. But Brave Jack is working at a farm shall not include brave. Convert pronouns to nouns where possible. If a subject or object cannot be identified, label it as unidentified.\\n{text}\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    if completion.choices:\n",
    "        response_message = str(completion.choices[0].message.content)\n",
    "        # process response_message from string to JSON\n",
    "        response_message = json.loads(response_message)\n",
    "        return response_message\n",
    "    else:\n",
    "        print(\"No response received.\")\n",
    "        return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'subject': 'mihai surdeanu', 'verb': 'is', 'object': 'associate professor'}, {'subject': 'mihai surdeanu', 'verb': 'is in', 'object': 'departments'}, {'subject': 'departments', 'verb': 'include', 'object': 'cognitive science - gidp'}, {'subject': 'departments', 'verb': 'include', 'object': 'computer science'}, {'subject': 'departments', 'verb': 'include', 'object': 'bio5 institute'}, {'subject': 'mihai surdeanu', 'verb': 'earned', 'object': 'ph.d.'}, {'subject': 'ph.d.', 'verb': 'is in', 'object': 'computer science'}, {'subject': 'ph.d.', 'verb': 'is from', 'object': 'southern methodist university'}, {'subject': 'ph.d.', 'verb': 'is from', 'object': '2001'}, {'subject': 'mihai surdeanu', 'verb': 'has', 'object': 'experience'}, {'subject': 'experience', 'verb': 'is over', 'object': '15 years'}, {'subject': 'systems', 'verb': 'are driven by', 'object': 'nlp'}, {'subject': 'systems', 'verb': 'are driven by', 'object': 'machine learning'}, {'subject': 'mihai surdeanu', 'verb': 'has published', 'object': 'articles'}, {'subject': 'articles', 'verb': 'are', 'object': 'peer-reviewed'}, {'subject': 'articles', 'verb': 'are over', 'object': '80'}, {'subject': 'mihai surdeanu', 'verb': 'has been', 'object': 'leader'}, {'subject': 'mihai surdeanu', 'verb': 'has been', 'object': 'member'}, {'subject': 'teams', 'verb': 'ranked in', 'object': 'top three'}, {'subject': 'evaluations', 'verb': 'are of', 'object': 'end-user nlp systems'}, {'subject': 'end-user nlp systems', 'verb': 'include', 'object': 'question answering'}, {'subject': 'end-user nlp systems', 'verb': 'include', 'object': 'information extraction'}, {'subject': 'work', 'verb': 'has been funded by', 'object': 'government organizations'}, {'subject': 'work', 'verb': 'has been funded by', 'object': 'private foundations'}, {'subject': 'mihai surdeanu', 'verb': 'focuses on', 'object': 'nlp'}, {'subject': 'mihai surdeanu', 'verb': 'focuses on', 'object': 'machine learning'}]\n",
      "knowledge_graph.html\n"
     ]
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "import json\n",
    "\n",
    "def visualize_json(json_data):\n",
    "    net = Network(height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\")\n",
    "\n",
    "    if isinstance(json_data, str):\n",
    "        data = json.loads(json_data)\n",
    "    else:\n",
    "        data = json_data\n",
    "\n",
    "    for entry in data:\n",
    "        subject = entry.get('subject')\n",
    "        verb = entry.get('verb')\n",
    "        object = entry.get('object')\n",
    "\n",
    "        net.add_node(subject, title=subject, color='skyblue')\n",
    "        net.add_node(object, title=object, color='lightgreen')\n",
    "        net.add_edge(subject, object, title=verb)\n",
    "\n",
    "    net.show(\"knowledge_graph.html\", notebook=False)\n",
    "\n",
    "\n",
    "\n",
    "# Example text to analyze\n",
    "text = \"According to my knowledge, Mihai Surdeanu is an Associate Professor in the departments of Cognitive Science - GIDP, Computer Science, and BIO5 Institute at the University of Arizona. He earned his Ph.D. in Computer Science from Southern Methodist University in 2001 and has over 15 years of experience in building systems driven by natural language processing (NLP) and machine learning. Surdeanu has published over 80 peer-reviewed articles and has been a leader or member of teams that ranked in the top three at seven highly competitive international evaluations of end-user NLP systems such as question answering and information extraction. His work has been funded by several government organizations and private foundations. Surdeanu's research focuses on NLP and machine learning.\"\n",
    "# Extract information from the text\n",
    "json_data = extract_information(text)\n",
    "print(json_data)\n",
    "\n",
    "# Visualize the extracted information as a knowledge graph\n",
    "visualize_json(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knowledge_graph_comparison.html\n"
     ]
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "import json\n",
    "\n",
    "def visualize_comparison(source_json_data, output_json_data, display='both'):\n",
    "    net = Network(height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\")\n",
    "\n",
    "    # Parse JSON data\n",
    "    source_data = json.loads(source_json_data) if isinstance(source_json_data, str) else source_json_data\n",
    "    output_data = json.loads(output_json_data) if isinstance(output_json_data, str) else output_json_data\n",
    "\n",
    "    # Extract nodes and verbs from data\n",
    "    source_nodes = set(entry['subject'] for entry in source_data) | set(entry['object'] for entry in source_data)\n",
    "    output_nodes = set(entry['subject'] for entry in output_data) | set(entry['object'] for entry in output_data)\n",
    "    \n",
    "    # Determine common nodes\n",
    "    common_nodes = source_nodes & output_nodes\n",
    "    \n",
    "    # Function to add nodes and edges to the network\n",
    "    def add_nodes_edges(data, node_color):\n",
    "        for entry in data:\n",
    "            subject, verb, object = entry['subject'], entry['verb'], entry['object']\n",
    "            # Conditionally color nodes if they are common\n",
    "            sub_color = 'yellow' if subject in common_nodes else node_color\n",
    "            obj_color = 'yellow' if object in common_nodes else node_color\n",
    "            net.add_node(subject, title=subject, color=sub_color)\n",
    "            net.add_node(object, title=object, color=obj_color)\n",
    "            net.add_edge(subject, object, title=verb)\n",
    "\n",
    "    # Add source graph nodes and edges\n",
    "    if display in ['source', 'both']:\n",
    "        add_nodes_edges(source_data, 'blue')\n",
    "\n",
    "    # Add output graph nodes and edges\n",
    "    if display in ['output', 'both']:\n",
    "        add_nodes_edges(output_data, 'green')\n",
    "\n",
    "    # Save and show the graph\n",
    "    net.show(\"knowledge_graph_comparison.html\", notebook=False)\n",
    "\n",
    "# Example JSON data for source and output\n",
    "source_json = json.dumps([\n",
    "    {\"subject\": \"Fox\", \"verb\": \"jumps\", \"object\": \"Dog\"},\n",
    "    {\"subject\": \"Dog\", \"verb\": \"barks\", \"object\": \"loudly\"}\n",
    "])\n",
    "\n",
    "output_json = json.dumps([\n",
    "    {\"subject\": \"Fox\", \"verb\": \"runs\", \"object\": \"fast\"},\n",
    "    {\"subject\": \"Dog\", \"verb\": \"barks\", \"object\": \"quietly\"}\n",
    "])\n",
    "\n",
    "# Visualize comparison allowing the user to choose which parts to display\n",
    "visualize_comparison(source_json, output_json, display='both')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source JSON: [{'subject': 'jack', 'verb': 'live', 'object': 'village'}, {'subject': 'jack', 'verb': 'be known', 'object': 'bravery kindness'}, {'subject': 'jack', 'verb': 'decide', 'object': 'climb'}, {'subject': 'beanstalk', 'verb': 'grow', 'object': 'backyard'}, {'subject': 'jack', 'verb': 'find', 'object': 'castle'}, {'subject': 'castle', 'verb': 'be inhabited', 'object': 'giant'}, {'subject': 'giant', 'verb': 'have', 'object': 'hen'}, {'subject': 'hen', 'verb': 'lay', 'object': 'eggs'}, {'subject': 'jack', 'verb': 'manage to steal', 'object': 'hen'}, {'subject': 'jack', 'verb': 'escape', 'object': 'giant'}, {'subject': 'giant', 'verb': 'chase', 'object': 'jack'}, {'subject': 'jack', 'verb': 'manage to cut down', 'object': 'beanstalk'}, {'subject': 'giant', 'verb': 'fall', 'object': 'doom'}, {'subject': 'jack', 'verb': 'return', 'object': 'village'}, {'subject': 'jack', 'verb': 'live', 'object': 'happily'}]\n",
      "Output JSON: [{'subject': 'jack', 'verb': 'live', 'object': 'kingman'}, {'subject': 'jack', 'verb': 'ascend', 'object': 'beanstalk'}, {'subject': 'jack', 'verb': 'discover', 'object': 'castle'}, {'subject': 'giant', 'verb': 'possess', 'object': 'hen'}, {'subject': 'jack', 'verb': 'capture', 'object': 'hen'}, {'subject': 'giant', 'verb': 'pursue', 'object': 'jack'}, {'subject': 'jack', 'verb': 'chop down', 'object': 'beanstalk'}, {'subject': 'jack', 'verb': 'return', 'object': 'village'}, {'subject': 'jack', 'verb': 'enjoy', 'object': 'life'}]\n",
      "knowledge_graph_comparison.html\n"
     ]
    }
   ],
   "source": [
    "# Generate source text\n",
    "source_text = \"There was once a boy named Jack who lived in a small village. Jack was known for his bravery and kindness. One day, Jack decided to climb a giant beanstalk that had grown in his backyard. At the top of the beanstalk, he found a castle inhabited by a giant. The giant had a magical hen that laid golden eggs. Jack managed to steal the hen and escape from the giant. The giant chased Jack down the beanstalk, but Jack managed to cut it down, causing the giant to fall to his doom. Jack returned to his village with the magical hen and lived happily ever after.\"\n",
    "\n",
    "# Generate output text with subtle hallucinations\n",
    "output_text = \"In the town of Kingman, Arizona, there lived a courageous and kind-hearted boy named Jack. One adventurous day, he ascended a massive beanstalk sprouting in his backyard. At its peak, Jack discovered a castle, home to a formidable giant. This giant possessed a hen with the ability to produce golden eggs. Jack cleverly captured the hen and fled from the giant's clutches. In a thrilling chase, the giant pursued Jack along the beanstalk. In a daring move, Jack chopped down the beanstalk, leading to the giant's tragic fall and demise. Triumphantly, Jack returned to his village, where he and the magical hen enjoyed a prosperous and joyful life.\"\n",
    "\n",
    "# Extract information from source text\n",
    "source_json = extract_information(source_text)\n",
    "output_json = extract_information(output_text)\n",
    "\n",
    "print(\"Source JSON:\", source_json)\n",
    "print(\"Output JSON:\", output_json)\n",
    "\n",
    "# Compare the graphs\n",
    "visualize_comparison(source_json, output_json, display='both')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
